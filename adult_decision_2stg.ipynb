{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fPtWMrHIl5tu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 2, 'name': 'Adult', 'repository_url': 'https://archive.ics.uci.edu/dataset/2/adult', 'data_url': 'https://archive.ics.uci.edu/static/public/2/data.csv', 'abstract': 'Predict whether annual income of an individual exceeds $50K/yr based on census data. Also known as \"Census Income\" dataset. ', 'area': 'Social Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 48842, 'num_features': 14, 'feature_types': ['Categorical', 'Integer'], 'demographics': ['Age', 'Income', 'Education Level', 'Other', 'Race', 'Sex'], 'target_col': ['income'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 1996, 'last_updated': 'Tue Sep 24 2024', 'dataset_doi': '10.24432/C5XW20', 'creators': ['Barry Becker', 'Ronny Kohavi'], 'intro_paper': None, 'additional_info': {'summary': \"Extraction was done by Barry Becker from the 1994 Census database.  A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\\n\\nPrediction task is to determine whether a person's income is over $50,000 a year.\\n\", 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Listing of attributes:\\r\\n\\r\\n>50K, <=50K.\\r\\n\\r\\nage: continuous.\\r\\nworkclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\\r\\nfnlwgt: continuous.\\r\\neducation: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\\r\\neducation-num: continuous.\\r\\nmarital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\\r\\noccupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\\r\\nrelationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\\r\\nrace: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\\r\\nsex: Female, Male.\\r\\ncapital-gain: continuous.\\r\\ncapital-loss: continuous.\\r\\nhours-per-week: continuous.\\r\\nnative-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.', 'citation': None}}\n",
      "              name     role         type      demographic  \\\n",
      "0              age  Feature      Integer              Age   \n",
      "1        workclass  Feature  Categorical           Income   \n",
      "2           fnlwgt  Feature      Integer             None   \n",
      "3        education  Feature  Categorical  Education Level   \n",
      "4    education-num  Feature      Integer  Education Level   \n",
      "5   marital-status  Feature  Categorical            Other   \n",
      "6       occupation  Feature  Categorical            Other   \n",
      "7     relationship  Feature  Categorical            Other   \n",
      "8             race  Feature  Categorical             Race   \n",
      "9              sex  Feature       Binary              Sex   \n",
      "10    capital-gain  Feature      Integer             None   \n",
      "11    capital-loss  Feature      Integer             None   \n",
      "12  hours-per-week  Feature      Integer             None   \n",
      "13  native-country  Feature  Categorical            Other   \n",
      "14          income   Target       Binary           Income   \n",
      "\n",
      "                                          description units missing_values  \n",
      "0                                                 N/A  None             no  \n",
      "1   Private, Self-emp-not-inc, Self-emp-inc, Feder...  None            yes  \n",
      "2                                                None  None             no  \n",
      "3    Bachelors, Some-college, 11th, HS-grad, Prof-...  None             no  \n",
      "4                                                None  None             no  \n",
      "5   Married-civ-spouse, Divorced, Never-married, S...  None             no  \n",
      "6   Tech-support, Craft-repair, Other-service, Sal...  None            yes  \n",
      "7   Wife, Own-child, Husband, Not-in-family, Other...  None             no  \n",
      "8   White, Asian-Pac-Islander, Amer-Indian-Eskimo,...  None             no  \n",
      "9                                       Female, Male.  None             no  \n",
      "10                                               None  None             no  \n",
      "11                                               None  None             no  \n",
      "12                                               None  None             no  \n",
      "13  United-States, Cambodia, England, Puerto-Rico,...  None            yes  \n",
      "14                                       >50K, <=50K.  None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "adult = fetch_ucirepo(id=2) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "df = adult.data.features \n",
    "y  = adult.data.targets.to_numpy() \n",
    "  \n",
    "# metadata \n",
    "print(adult.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(adult.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "SKCsRg7xloiA",
    "outputId": "c2c6ac75-378f-4c31-a9ed-e66f82331ec5"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('adult.data')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "QeZTeRpXnK4l",
    "outputId": "0a74dabf-9a37-4c41-d6b0-41f31854dad0"
   },
   "outputs": [],
   "source": [
    "# df['charges'] = df['charges'].apply(lambda x: 1 if x >= 10000 else 0)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country  \n",
       "0          2174             0              40  United-States  \n",
       "1             0             0              13  United-States  \n",
       "2             0             0              40  United-States  \n",
       "3             0             0              40  United-States  \n",
       "4             0             0              40           Cuba  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['<=50K', '<=50K.', '>50K', '>50K.'], dtype=object),\n",
       " array([24720, 12435,  7841,  3846]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = list(y)\n",
    "for i in range(len(y)):\n",
    "    if y[i] == '<=50K' or y[i] == '<=50K.':\n",
    "        y[i] = 0\n",
    "    else:\n",
    "        y[i] = 1\n",
    "        \n",
    "y = np.array(y)\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>321403</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt  education  education-num  \\\n",
       "0       39         State-gov   77516  Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2       38           Private  215646    HS-grad              9   \n",
       "3       53           Private  234721       11th              7   \n",
       "4       28           Private  338409  Bachelors             13   \n",
       "...    ...               ...     ...        ...            ...   \n",
       "48837   39           Private  215419  Bachelors             13   \n",
       "48838   64               NaN  321403    HS-grad              9   \n",
       "48839   38           Private  374983  Bachelors             13   \n",
       "48840   44           Private   83891  Bachelors             13   \n",
       "48841   35      Self-emp-inc  182148  Bachelors             13   \n",
       "\n",
       "           marital-status         occupation    relationship  \\\n",
       "0           Never-married       Adm-clerical   Not-in-family   \n",
       "1      Married-civ-spouse    Exec-managerial         Husband   \n",
       "2                Divorced  Handlers-cleaners   Not-in-family   \n",
       "3      Married-civ-spouse  Handlers-cleaners         Husband   \n",
       "4      Married-civ-spouse     Prof-specialty            Wife   \n",
       "...                   ...                ...             ...   \n",
       "48837            Divorced     Prof-specialty   Not-in-family   \n",
       "48838             Widowed                NaN  Other-relative   \n",
       "48839  Married-civ-spouse     Prof-specialty         Husband   \n",
       "48840            Divorced       Adm-clerical       Own-child   \n",
       "48841  Married-civ-spouse    Exec-managerial         Husband   \n",
       "\n",
       "                     race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0                   White    Male          2174             0              40   \n",
       "1                   White    Male             0             0              13   \n",
       "2                   White    Male             0             0              40   \n",
       "3                   Black    Male             0             0              40   \n",
       "4                   Black  Female             0             0              40   \n",
       "...                   ...     ...           ...           ...             ...   \n",
       "48837               White  Female             0             0              36   \n",
       "48838               Black    Male             0             0              40   \n",
       "48839               White    Male             0             0              50   \n",
       "48840  Asian-Pac-Islander    Male          5455             0              40   \n",
       "48841               White    Male             0             0              60   \n",
       "\n",
       "      native-country  income  \n",
       "0      United-States       0  \n",
       "1      United-States       0  \n",
       "2      United-States       0  \n",
       "3      United-States       0  \n",
       "4               Cuba       0  \n",
       "...              ...     ...  \n",
       "48837  United-States       0  \n",
       "48838  United-States       0  \n",
       "48839  United-States       0  \n",
       "48840  United-States       0  \n",
       "48841  United-States       1  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['income'] = y\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'capital-gain': 'capital gain', 'capital-loss': 'capital loss', 'native-country': 'country','hours-per-week': 'hours per week','marital-status': 'marital'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  0\n",
       "workclass         1836\n",
       "fnlwgt               0\n",
       "education            0\n",
       "education-num        0\n",
       "marital              0\n",
       "occupation        1843\n",
       "relationship         0\n",
       "race                 0\n",
       "sex                  0\n",
       "capital gain         0\n",
       "capital loss         0\n",
       "hours per week       0\n",
       "country            583\n",
       "income               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isin(['?']).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code will replace the special character to nan and then drop the columns \n",
    "df['country'] = df['country'].replace('?',np.nan)\n",
    "df['workclass'] = df['workclass'].replace('?',np.nan)\n",
    "df['occupation'] = df['occupation'].replace('?',np.nan)\n",
    "#dropping the NaN rows now \n",
    "df.dropna(how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.crosstab(df.education,df.income).plot(kind='bar')\n",
    "plt.title('Purchase Frequency w.r.t Education')\n",
    "plt.xlabel('Education')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['workclass', 'education', 'marital', \\\n",
    "            'occupation', 'relationship', 'race', 'sex', 'country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ju78RIFTmF9y"
   },
   "outputs": [],
   "source": [
    "def one_hot(df, cols): # idk if sklearns one-hot encoder is similar\n",
    "    \"\"\"\n",
    "    df: pandas DataFrame\n",
    "    param: cols a list of columns to encode\n",
    "    return a DataFrame with one-hot encoding\n",
    "    \"\"\"\n",
    "    for each in cols:\n",
    "        dummies = pd.get_dummies(df[each], prefix=each, drop_first=False)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "TMeE84WimVq_"
   },
   "outputs": [],
   "source": [
    "def numeric_scaler(df, cols):\n",
    "    '''\n",
    "    df: pandas dataframe\n",
    "    numeric_cols: (array of strings) column names for numeric variables\n",
    "\n",
    "    no return: does inplace operation\n",
    "    '''\n",
    "    df_new = df.copy()\n",
    "    mmscaler = MinMaxScaler()\n",
    "    df_new[cols] = mmscaler.fit_transform(df_new[cols])\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital gain</th>\n",
       "      <th>capital loss</th>\n",
       "      <th>hours per week</th>\n",
       "      <th>country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "              marital         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital gain  capital loss  hours per week        country  income  \n",
       "0          2174             0              40  United-States       0  \n",
       "1             0             0              13  United-States       0  \n",
       "2             0             0              40  United-States       0  \n",
       "3             0             0              40  United-States       0  \n",
       "4             0             0              40           Cuba       0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "48836    0\n",
       "48837    0\n",
       "48839    0\n",
       "48840    0\n",
       "48841    1\n",
       "Name: income, Length: 45222, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['income']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qk7vt7Zfl2nV"
   },
   "outputs": [],
   "source": [
    "numeric_all = ['age', 'bmi', 'children', 'charges']\n",
    "# cat_all = ['sex', 'smoker', 'region']\n",
    "# df_medical_mm = numeric_scaler(df, numeric_all) # minmax scaling for all numeric columns, so all elements in [0,1]\n",
    "df_medical_mm_oh = one_hot(df, cat_cols)\n",
    "df_medical_mm_oh.drop(cat_cols, axis = 1, inplace=True) # drop categories that were used to one hot encode\n",
    "df_medical_mm_oh = df_medical_mm_oh * 1.0 # make bool true, false into 1.0, 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital gain</th>\n",
       "      <th>capital loss</th>\n",
       "      <th>hours per week</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>...</th>\n",
       "      <th>country_Portugal</th>\n",
       "      <th>country_Puerto-Rico</th>\n",
       "      <th>country_Scotland</th>\n",
       "      <th>country_South</th>\n",
       "      <th>country_Taiwan</th>\n",
       "      <th>country_Thailand</th>\n",
       "      <th>country_Trinadad&amp;Tobago</th>\n",
       "      <th>country_United-States</th>\n",
       "      <th>country_Vietnam</th>\n",
       "      <th>country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.0</td>\n",
       "      <td>77516.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>83311.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>215646.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.0</td>\n",
       "      <td>234721.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.0</td>\n",
       "      <td>338409.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    fnlwgt  education-num  capital gain  capital loss  hours per week  \\\n",
       "0  39.0   77516.0           13.0        2174.0           0.0            40.0   \n",
       "1  50.0   83311.0           13.0           0.0           0.0            13.0   \n",
       "2  38.0  215646.0            9.0           0.0           0.0            40.0   \n",
       "3  53.0  234721.0            7.0           0.0           0.0            40.0   \n",
       "4  28.0  338409.0           13.0           0.0           0.0            40.0   \n",
       "\n",
       "   income  workclass_Federal-gov  workclass_Local-gov  workclass_Private  ...  \\\n",
       "0     0.0                    0.0                  0.0                0.0  ...   \n",
       "1     0.0                    0.0                  0.0                0.0  ...   \n",
       "2     0.0                    0.0                  0.0                1.0  ...   \n",
       "3     0.0                    0.0                  0.0                1.0  ...   \n",
       "4     0.0                    0.0                  0.0                1.0  ...   \n",
       "\n",
       "   country_Portugal  country_Puerto-Rico  country_Scotland  country_South  \\\n",
       "0               0.0                  0.0               0.0            0.0   \n",
       "1               0.0                  0.0               0.0            0.0   \n",
       "2               0.0                  0.0               0.0            0.0   \n",
       "3               0.0                  0.0               0.0            0.0   \n",
       "4               0.0                  0.0               0.0            0.0   \n",
       "\n",
       "   country_Taiwan  country_Thailand  country_Trinadad&Tobago  \\\n",
       "0             0.0               0.0                      0.0   \n",
       "1             0.0               0.0                      0.0   \n",
       "2             0.0               0.0                      0.0   \n",
       "3             0.0               0.0                      0.0   \n",
       "4             0.0               0.0                      0.0   \n",
       "\n",
       "   country_United-States  country_Vietnam  country_Yugoslavia  \n",
       "0                    1.0              0.0                 0.0  \n",
       "1                    1.0              0.0                 0.0  \n",
       "2                    1.0              0.0                 0.0  \n",
       "3                    1.0              0.0                 0.0  \n",
       "4                    0.0              0.0                 0.0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_medical_mm_oh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45222, 105)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_medical_mm_oh\n",
    "# X['intercept'] = 1.0\n",
    "X = X.to_numpy() # now (n, d+1) dimensional, log regression in d+1 is affine in d\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.90000e+01, 7.75160e+04, 1.30000e+01, ..., 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [5.00000e+01, 8.33110e+04, 1.30000e+01, ..., 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [3.80000e+01, 2.15646e+05, 9.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       ...,\n",
       "       [3.80000e+01, 3.74983e+05, 1.30000e+01, ..., 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [4.40000e+01, 8.38910e+04, 1.30000e+01, ..., 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [3.50000e+01, 1.82148e+05, 1.30000e+01, ..., 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns(X):\n",
    "    # Calculate the L2 norm of each column\n",
    "    col_norms = np.linalg.norm(X, ord=2, axis=0)\n",
    "    \n",
    "    # Find scaling factors where norm > 1\n",
    "    scaling_factors = np.maximum(col_norms, 1.0)  # Ensures norms <= 1\n",
    "    \n",
    "    # Scale columns with their respective factors\n",
    "    X_normalized = X / scaling_factors\n",
    "    return X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00450039, 0.00167856, 0.00585806, ..., 0.00492115, 0.        ,\n",
       "        0.        ],\n",
       "       [0.00576973, 0.00180404, 0.00585806, ..., 0.00492115, 0.        ,\n",
       "        0.        ],\n",
       "       [0.004385  , 0.00466967, 0.00405558, ..., 0.00492115, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.004385  , 0.00812   , 0.00585806, ..., 0.00492115, 0.        ,\n",
       "        0.        ],\n",
       "       [0.00507737, 0.0018166 , 0.00585806, ..., 0.00492115, 0.        ,\n",
       "        0.        ],\n",
       "       [0.00403881, 0.00394429, 0.00585806, ..., 0.00492115, 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = normalize_columns(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(X, ord=2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13318725 0.04967615 0.1733669  ... 0.14563953 0.         0.        ]\n",
      " [0.20157255 0.06302637 0.20465839 ... 0.17192643 0.         0.        ]\n",
      " [0.13934396 0.14838997 0.12887595 ... 0.15638165 0.         0.        ]\n",
      " ...\n",
      " [0.17040585 0.31555208 0.22765073 ... 0.1912415  0.         0.        ]\n",
      " [0.12809796 0.04583144 0.1477943  ... 0.12415687 0.         0.        ]\n",
      " [0.11246553 0.10983339 0.16312463 ... 0.13703536 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "normalizer = Normalizer()\n",
    "X = normalizer.fit_transform(X)\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212.65464960823303"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212.65464960823218"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.sqrt(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "48836    0\n",
       "48837    0\n",
       "48839    0\n",
       "48840    0\n",
       "48841    1\n",
       "Name: income, Length: 45222, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = np.where(y == '<=50K', 0, 1)\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38zT1ksynd_u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kYSSBvBthirg",
    "outputId": "595b80cd-8675-48a5-d5fb-f3fe758376fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data x, y shapes (40699, 105) (40699,)\n",
      "Test data x, y shapes (4523, 105) (4523,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=43)\n",
    "print(\"Training data x, y shapes\", X_train.shape, y_train.shape)\n",
    "print(\"Test data x, y shapes\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogReg, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(input_dim, output_dim, bias=True)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.sigmoid(x)  # Apply sigmoid to bound outputs between 0 and 1\n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \n",
    "    # Compute sigmoid: 1 / (1 + e^(-x))\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "\n",
    "def twostg_train_model(X_train, y_train, eps_p, lr, epochs, Lamb, batch_size=128):\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train = np.array(y_train)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "    n, d =  X_train.shape[0], X_train.shape[1]\n",
    "    \n",
    "    model = LogReg(d, 1)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    \n",
    "    theta_init = torch.randn((d,1),requires_grad=True)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    eps_dash_p = eps_p - (2 * np.log(1 + (1 / (n * Lamb))))\n",
    "\n",
    "    if eps_dash_p > 0:\n",
    "        Delta = 0\n",
    "    else:\n",
    "        Delta = (1 / (np.exp(eps_p / 4) - 1)) - Lamb\n",
    "        eps_dash_p = eps_p / 2\n",
    "\n",
    "    eta = eps_dash_p / (6 * math.sqrt(n))\n",
    "\n",
    "    b = np.random.gamma(d, scale=1.0 / eta, size=(d+1, 1))\n",
    "    b = torch.Tensor(b.reshape(1, -1))\n",
    "    \n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc='Training'):\n",
    "        model.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        outputs = model(X_train_tensor)\n",
    "\n",
    "        theta = torch.cat([p.flatten() for p in model.parameters()])\n",
    "\n",
    "        pert = (1 / n) * torch.dot(b.flatten(), theta.flatten())\n",
    "\n",
    "        loss = (\n",
    "            criterion(outputs.flatten(), y_train_tensor.flatten())\n",
    "            + pert\n",
    "            + ((Lamb + Delta) * (torch.norm(theta, p=2) ** 2))\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                train_pred = model(X_train_tensor)\n",
    "                train_pred_cls = train_pred.round()\n",
    "                train_acc = (train_pred_cls == y_train_tensor).float().mean()\n",
    "                print(f'Epoch [{epoch+1}/{epochs}], '\n",
    "                      f'Loss: {loss.item():.4f}, '\n",
    "                      f'Train Acc: {train_acc:.4f}, ')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏                            | 78/10000 [00:00<00:33, 297.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10000], Loss: 0.7012, Train Acc: 0.4066, \n",
      "Epoch [20/10000], Loss: 0.6909, Train Acc: 0.5541, \n",
      "Epoch [30/10000], Loss: 0.6809, Train Acc: 0.6803, \n",
      "Epoch [40/10000], Loss: 0.6714, Train Acc: 0.7405, \n",
      "Epoch [50/10000], Loss: 0.6623, Train Acc: 0.7597, \n",
      "Epoch [60/10000], Loss: 0.6536, Train Acc: 0.7603, \n",
      "Epoch [70/10000], Loss: 0.6453, Train Acc: 0.7592, \n",
      "Epoch [80/10000], Loss: 0.6374, Train Acc: 0.7586, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▍                           | 156/10000 [00:00<00:28, 351.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/10000], Loss: 0.6298, Train Acc: 0.7580, \n",
      "Epoch [100/10000], Loss: 0.6225, Train Acc: 0.7575, \n",
      "Epoch [110/10000], Loss: 0.6155, Train Acc: 0.7568, \n",
      "Epoch [120/10000], Loss: 0.6088, Train Acc: 0.7564, \n",
      "Epoch [130/10000], Loss: 0.6024, Train Acc: 0.7566, \n",
      "Epoch [140/10000], Loss: 0.5962, Train Acc: 0.7568, \n",
      "Epoch [150/10000], Loss: 0.5902, Train Acc: 0.7571, \n",
      "Epoch [160/10000], Loss: 0.5844, Train Acc: 0.7572, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▋                           | 236/10000 [00:00<00:25, 376.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [170/10000], Loss: 0.5789, Train Acc: 0.7576, \n",
      "Epoch [180/10000], Loss: 0.5735, Train Acc: 0.7584, \n",
      "Epoch [190/10000], Loss: 0.5683, Train Acc: 0.7590, \n",
      "Epoch [200/10000], Loss: 0.5633, Train Acc: 0.7595, \n",
      "Epoch [210/10000], Loss: 0.5585, Train Acc: 0.7600, \n",
      "Epoch [220/10000], Loss: 0.5537, Train Acc: 0.7607, \n",
      "Epoch [230/10000], Loss: 0.5492, Train Acc: 0.7614, \n",
      "Epoch [240/10000], Loss: 0.5448, Train Acc: 0.7624, \n",
      "Epoch [250/10000], Loss: 0.5405, Train Acc: 0.7638, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▉                           | 319/10000 [00:00<00:25, 383.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [260/10000], Loss: 0.5363, Train Acc: 0.7654, \n",
      "Epoch [270/10000], Loss: 0.5323, Train Acc: 0.7670, \n",
      "Epoch [280/10000], Loss: 0.5283, Train Acc: 0.7689, \n",
      "Epoch [290/10000], Loss: 0.5245, Train Acc: 0.7706, \n",
      "Epoch [300/10000], Loss: 0.5208, Train Acc: 0.7727, \n",
      "Epoch [310/10000], Loss: 0.5172, Train Acc: 0.7743, \n",
      "Epoch [320/10000], Loss: 0.5137, Train Acc: 0.7755, \n",
      "Epoch [330/10000], Loss: 0.5103, Train Acc: 0.7766, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|█                           | 396/10000 [00:01<00:28, 342.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [340/10000], Loss: 0.5069, Train Acc: 0.7777, \n",
      "Epoch [350/10000], Loss: 0.5037, Train Acc: 0.7784, \n",
      "Epoch [360/10000], Loss: 0.5005, Train Acc: 0.7791, \n",
      "Epoch [370/10000], Loss: 0.4975, Train Acc: 0.7803, \n",
      "Epoch [380/10000], Loss: 0.4945, Train Acc: 0.7811, \n",
      "Epoch [390/10000], Loss: 0.4915, Train Acc: 0.7821, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|█▏                          | 431/10000 [00:01<00:29, 324.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [400/10000], Loss: 0.4887, Train Acc: 0.7833, \n",
      "Epoch [410/10000], Loss: 0.4859, Train Acc: 0.7844, \n",
      "Epoch [420/10000], Loss: 0.4832, Train Acc: 0.7856, \n",
      "Epoch [430/10000], Loss: 0.4805, Train Acc: 0.7868, \n",
      "Epoch [440/10000], Loss: 0.4779, Train Acc: 0.7879, \n",
      "Epoch [450/10000], Loss: 0.4754, Train Acc: 0.7890, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|█▍                          | 499/10000 [00:01<00:29, 325.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [460/10000], Loss: 0.4729, Train Acc: 0.7902, \n",
      "Epoch [470/10000], Loss: 0.4705, Train Acc: 0.7912, \n",
      "Epoch [480/10000], Loss: 0.4682, Train Acc: 0.7924, \n",
      "Epoch [490/10000], Loss: 0.4659, Train Acc: 0.7940, \n",
      "Epoch [500/10000], Loss: 0.4636, Train Acc: 0.7954, \n",
      "Epoch [510/10000], Loss: 0.4614, Train Acc: 0.7969, \n",
      "Epoch [520/10000], Loss: 0.4592, Train Acc: 0.7987, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|█▌                          | 575/10000 [00:01<00:26, 354.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [530/10000], Loss: 0.4571, Train Acc: 0.8001, \n",
      "Epoch [540/10000], Loss: 0.4550, Train Acc: 0.8020, \n",
      "Epoch [550/10000], Loss: 0.4530, Train Acc: 0.8038, \n",
      "Epoch [560/10000], Loss: 0.4510, Train Acc: 0.8054, \n",
      "Epoch [570/10000], Loss: 0.4490, Train Acc: 0.8069, \n",
      "Epoch [580/10000], Loss: 0.4471, Train Acc: 0.8081, \n",
      "Epoch [590/10000], Loss: 0.4452, Train Acc: 0.8094, \n",
      "Epoch [600/10000], Loss: 0.4434, Train Acc: 0.8104, \n",
      "Epoch [610/10000], Loss: 0.4416, Train Acc: 0.8115, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|█▊                          | 663/10000 [00:01<00:23, 396.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [620/10000], Loss: 0.4398, Train Acc: 0.8124, \n",
      "Epoch [630/10000], Loss: 0.4381, Train Acc: 0.8133, \n",
      "Epoch [640/10000], Loss: 0.4363, Train Acc: 0.8142, \n",
      "Epoch [650/10000], Loss: 0.4347, Train Acc: 0.8147, \n",
      "Epoch [660/10000], Loss: 0.4330, Train Acc: 0.8157, \n",
      "Epoch [670/10000], Loss: 0.4314, Train Acc: 0.8168, \n",
      "Epoch [680/10000], Loss: 0.4298, Train Acc: 0.8177, \n",
      "Epoch [690/10000], Loss: 0.4282, Train Acc: 0.8186, \n",
      "Epoch [700/10000], Loss: 0.4267, Train Acc: 0.8198, \n",
      "Epoch [710/10000], Loss: 0.4252, Train Acc: 0.8210, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|██▏                         | 762/10000 [00:02<00:20, 442.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [720/10000], Loss: 0.4237, Train Acc: 0.8217, \n",
      "Epoch [730/10000], Loss: 0.4222, Train Acc: 0.8222, \n",
      "Epoch [740/10000], Loss: 0.4208, Train Acc: 0.8224, \n",
      "Epoch [750/10000], Loss: 0.4193, Train Acc: 0.8226, \n",
      "Epoch [760/10000], Loss: 0.4179, Train Acc: 0.8235, \n",
      "Epoch [770/10000], Loss: 0.4166, Train Acc: 0.8236, \n",
      "Epoch [780/10000], Loss: 0.4152, Train Acc: 0.8240, \n",
      "Epoch [790/10000], Loss: 0.4139, Train Acc: 0.8244, \n",
      "Epoch [800/10000], Loss: 0.4126, Train Acc: 0.8247, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|██▍                         | 850/10000 [00:02<00:23, 383.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [810/10000], Loss: 0.4113, Train Acc: 0.8255, \n",
      "Epoch [820/10000], Loss: 0.4100, Train Acc: 0.8261, \n",
      "Epoch [830/10000], Loss: 0.4087, Train Acc: 0.8264, \n",
      "Epoch [840/10000], Loss: 0.4075, Train Acc: 0.8269, \n",
      "Epoch [850/10000], Loss: 0.4063, Train Acc: 0.8273, \n",
      "Epoch [860/10000], Loss: 0.4051, Train Acc: 0.8278, \n",
      "Epoch [870/10000], Loss: 0.4039, Train Acc: 0.8283, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|██▌                         | 932/10000 [00:02<00:23, 387.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [880/10000], Loss: 0.4027, Train Acc: 0.8289, \n",
      "Epoch [890/10000], Loss: 0.4016, Train Acc: 0.8297, \n",
      "Epoch [900/10000], Loss: 0.4004, Train Acc: 0.8302, \n",
      "Epoch [910/10000], Loss: 0.3993, Train Acc: 0.8309, \n",
      "Epoch [920/10000], Loss: 0.3982, Train Acc: 0.8315, \n",
      "Epoch [930/10000], Loss: 0.3971, Train Acc: 0.8321, \n",
      "Epoch [940/10000], Loss: 0.3960, Train Acc: 0.8326, \n",
      "Epoch [950/10000], Loss: 0.3950, Train Acc: 0.8331, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|██▋                        | 1011/10000 [00:02<00:23, 381.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [960/10000], Loss: 0.3939, Train Acc: 0.8337, \n",
      "Epoch [970/10000], Loss: 0.3929, Train Acc: 0.8341, \n",
      "Epoch [980/10000], Loss: 0.3919, Train Acc: 0.8343, \n",
      "Epoch [990/10000], Loss: 0.3909, Train Acc: 0.8346, \n",
      "Epoch [1000/10000], Loss: 0.3899, Train Acc: 0.8348, \n",
      "Epoch [1010/10000], Loss: 0.3889, Train Acc: 0.8351, \n",
      "Epoch [1020/10000], Loss: 0.3879, Train Acc: 0.8355, \n",
      "Epoch [1030/10000], Loss: 0.3869, Train Acc: 0.8359, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|██▉                        | 1092/10000 [00:02<00:23, 386.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1040/10000], Loss: 0.3860, Train Acc: 0.8363, \n",
      "Epoch [1050/10000], Loss: 0.3850, Train Acc: 0.8366, \n",
      "Epoch [1060/10000], Loss: 0.3841, Train Acc: 0.8369, \n",
      "Epoch [1070/10000], Loss: 0.3832, Train Acc: 0.8373, \n",
      "Epoch [1080/10000], Loss: 0.3823, Train Acc: 0.8375, \n",
      "Epoch [1090/10000], Loss: 0.3814, Train Acc: 0.8382, \n",
      "Epoch [1100/10000], Loss: 0.3805, Train Acc: 0.8386, \n",
      "Epoch [1110/10000], Loss: 0.3796, Train Acc: 0.8393, \n",
      "Epoch [1120/10000], Loss: 0.3788, Train Acc: 0.8399, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|███▏                       | 1177/10000 [00:03<00:21, 403.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1130/10000], Loss: 0.3779, Train Acc: 0.8402, \n",
      "Epoch [1140/10000], Loss: 0.3771, Train Acc: 0.8405, \n",
      "Epoch [1150/10000], Loss: 0.3762, Train Acc: 0.8410, \n",
      "Epoch [1160/10000], Loss: 0.3754, Train Acc: 0.8416, \n",
      "Epoch [1170/10000], Loss: 0.3746, Train Acc: 0.8420, \n",
      "Epoch [1180/10000], Loss: 0.3738, Train Acc: 0.8424, \n",
      "Epoch [1190/10000], Loss: 0.3730, Train Acc: 0.8430, \n",
      "Epoch [1200/10000], Loss: 0.3722, Train Acc: 0.8435, \n",
      "Epoch [1210/10000], Loss: 0.3714, Train Acc: 0.8442, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|███▍                       | 1258/10000 [00:03<00:23, 369.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1220/10000], Loss: 0.3706, Train Acc: 0.8447, \n",
      "Epoch [1230/10000], Loss: 0.3698, Train Acc: 0.8452, \n",
      "Epoch [1240/10000], Loss: 0.3691, Train Acc: 0.8457, \n",
      "Epoch [1250/10000], Loss: 0.3683, Train Acc: 0.8463, \n",
      "Epoch [1260/10000], Loss: 0.3676, Train Acc: 0.8469, \n",
      "Epoch [1270/10000], Loss: 0.3668, Train Acc: 0.8474, \n",
      "Epoch [1280/10000], Loss: 0.3661, Train Acc: 0.8481, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|███▌                       | 1334/10000 [00:03<00:23, 364.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1290/10000], Loss: 0.3654, Train Acc: 0.8485, \n",
      "Epoch [1300/10000], Loss: 0.3646, Train Acc: 0.8491, \n",
      "Epoch [1310/10000], Loss: 0.3639, Train Acc: 0.8496, \n",
      "Epoch [1320/10000], Loss: 0.3632, Train Acc: 0.8499, \n",
      "Epoch [1330/10000], Loss: 0.3625, Train Acc: 0.8502, \n",
      "Epoch [1340/10000], Loss: 0.3618, Train Acc: 0.8507, \n",
      "Epoch [1350/10000], Loss: 0.3612, Train Acc: 0.8510, \n",
      "Epoch [1360/10000], Loss: 0.3605, Train Acc: 0.8514, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|███▊                       | 1419/10000 [00:03<00:21, 390.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1370/10000], Loss: 0.3598, Train Acc: 0.8518, \n",
      "Epoch [1380/10000], Loss: 0.3591, Train Acc: 0.8522, \n",
      "Epoch [1390/10000], Loss: 0.3585, Train Acc: 0.8525, \n",
      "Epoch [1400/10000], Loss: 0.3578, Train Acc: 0.8529, \n",
      "Epoch [1410/10000], Loss: 0.3572, Train Acc: 0.8532, \n",
      "Epoch [1420/10000], Loss: 0.3565, Train Acc: 0.8537, \n",
      "Epoch [1430/10000], Loss: 0.3559, Train Acc: 0.8540, \n",
      "Epoch [1440/10000], Loss: 0.3552, Train Acc: 0.8543, \n",
      "Epoch [1450/10000], Loss: 0.3546, Train Acc: 0.8547, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|████                       | 1502/10000 [00:04<00:21, 401.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1460/10000], Loss: 0.3540, Train Acc: 0.8550, \n",
      "Epoch [1470/10000], Loss: 0.3534, Train Acc: 0.8553, \n",
      "Epoch [1480/10000], Loss: 0.3528, Train Acc: 0.8554, \n",
      "Epoch [1490/10000], Loss: 0.3522, Train Acc: 0.8556, \n",
      "Epoch [1500/10000], Loss: 0.3516, Train Acc: 0.8560, \n",
      "Epoch [1510/10000], Loss: 0.3510, Train Acc: 0.8563, \n",
      "Epoch [1520/10000], Loss: 0.3504, Train Acc: 0.8565, \n",
      "Epoch [1530/10000], Loss: 0.3498, Train Acc: 0.8567, \n",
      "Epoch [1540/10000], Loss: 0.3492, Train Acc: 0.8570, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|████▍                      | 1626/10000 [00:04<00:20, 406.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1550/10000], Loss: 0.3486, Train Acc: 0.8571, \n",
      "Epoch [1560/10000], Loss: 0.3480, Train Acc: 0.8573, \n",
      "Epoch [1570/10000], Loss: 0.3475, Train Acc: 0.8574, \n",
      "Epoch [1580/10000], Loss: 0.3469, Train Acc: 0.8577, \n",
      "Epoch [1590/10000], Loss: 0.3464, Train Acc: 0.8579, \n",
      "Epoch [1600/10000], Loss: 0.3458, Train Acc: 0.8581, \n",
      "Epoch [1610/10000], Loss: 0.3452, Train Acc: 0.8583, \n",
      "Epoch [1620/10000], Loss: 0.3447, Train Acc: 0.8584, \n",
      "Epoch [1630/10000], Loss: 0.3442, Train Acc: 0.8587, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|████▌                      | 1709/10000 [00:04<00:21, 389.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1640/10000], Loss: 0.3436, Train Acc: 0.8591, \n",
      "Epoch [1650/10000], Loss: 0.3431, Train Acc: 0.8593, \n",
      "Epoch [1660/10000], Loss: 0.3425, Train Acc: 0.8595, \n",
      "Epoch [1670/10000], Loss: 0.3420, Train Acc: 0.8596, \n",
      "Epoch [1680/10000], Loss: 0.3415, Train Acc: 0.8597, \n",
      "Epoch [1690/10000], Loss: 0.3410, Train Acc: 0.8598, \n",
      "Epoch [1700/10000], Loss: 0.3405, Train Acc: 0.8602, \n",
      "Epoch [1710/10000], Loss: 0.3399, Train Acc: 0.8605, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|████▊                      | 1803/10000 [00:04<00:19, 426.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1720/10000], Loss: 0.3394, Train Acc: 0.8607, \n",
      "Epoch [1730/10000], Loss: 0.3389, Train Acc: 0.8610, \n",
      "Epoch [1740/10000], Loss: 0.3384, Train Acc: 0.8612, \n",
      "Epoch [1750/10000], Loss: 0.3379, Train Acc: 0.8614, \n",
      "Epoch [1760/10000], Loss: 0.3374, Train Acc: 0.8618, \n",
      "Epoch [1770/10000], Loss: 0.3369, Train Acc: 0.8620, \n",
      "Epoch [1780/10000], Loss: 0.3364, Train Acc: 0.8622, \n",
      "Epoch [1790/10000], Loss: 0.3360, Train Acc: 0.8624, \n",
      "Epoch [1800/10000], Loss: 0.3355, Train Acc: 0.8625, \n",
      "Epoch [1810/10000], Loss: 0.3350, Train Acc: 0.8625, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█████                      | 1891/10000 [00:04<00:19, 425.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1820/10000], Loss: 0.3345, Train Acc: 0.8629, \n",
      "Epoch [1830/10000], Loss: 0.3340, Train Acc: 0.8631, \n",
      "Epoch [1840/10000], Loss: 0.3336, Train Acc: 0.8633, \n",
      "Epoch [1850/10000], Loss: 0.3331, Train Acc: 0.8634, \n",
      "Epoch [1860/10000], Loss: 0.3326, Train Acc: 0.8636, \n",
      "Epoch [1870/10000], Loss: 0.3322, Train Acc: 0.8638, \n",
      "Epoch [1880/10000], Loss: 0.3317, Train Acc: 0.8639, \n",
      "Epoch [1890/10000], Loss: 0.3313, Train Acc: 0.8640, \n",
      "Epoch [1900/10000], Loss: 0.3308, Train Acc: 0.8641, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█████▎                     | 1977/10000 [00:05<00:18, 424.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1910/10000], Loss: 0.3304, Train Acc: 0.8643, \n",
      "Epoch [1920/10000], Loss: 0.3299, Train Acc: 0.8644, \n",
      "Epoch [1930/10000], Loss: 0.3295, Train Acc: 0.8647, \n",
      "Epoch [1940/10000], Loss: 0.3290, Train Acc: 0.8649, \n",
      "Epoch [1950/10000], Loss: 0.3286, Train Acc: 0.8649, \n",
      "Epoch [1960/10000], Loss: 0.3281, Train Acc: 0.8650, \n",
      "Epoch [1970/10000], Loss: 0.3277, Train Acc: 0.8652, \n",
      "Epoch [1980/10000], Loss: 0.3273, Train Acc: 0.8654, \n",
      "Epoch [1990/10000], Loss: 0.3268, Train Acc: 0.8655, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|█████▌                     | 2064/10000 [00:05<00:18, 424.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2000/10000], Loss: 0.3264, Train Acc: 0.8658, \n",
      "Epoch [2010/10000], Loss: 0.3260, Train Acc: 0.8659, \n",
      "Epoch [2020/10000], Loss: 0.3256, Train Acc: 0.8661, \n",
      "Epoch [2030/10000], Loss: 0.3251, Train Acc: 0.8663, \n",
      "Epoch [2040/10000], Loss: 0.3247, Train Acc: 0.8668, \n",
      "Epoch [2050/10000], Loss: 0.3243, Train Acc: 0.8669, \n",
      "Epoch [2060/10000], Loss: 0.3239, Train Acc: 0.8670, \n",
      "Epoch [2070/10000], Loss: 0.3235, Train Acc: 0.8671, \n",
      "Epoch [2080/10000], Loss: 0.3231, Train Acc: 0.8672, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|█████▊                     | 2155/10000 [00:05<00:18, 433.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2090/10000], Loss: 0.3227, Train Acc: 0.8674, \n",
      "Epoch [2100/10000], Loss: 0.3223, Train Acc: 0.8675, \n",
      "Epoch [2110/10000], Loss: 0.3219, Train Acc: 0.8676, \n",
      "Epoch [2120/10000], Loss: 0.3214, Train Acc: 0.8678, \n",
      "Epoch [2130/10000], Loss: 0.3210, Train Acc: 0.8679, \n",
      "Epoch [2140/10000], Loss: 0.3207, Train Acc: 0.8681, \n",
      "Epoch [2150/10000], Loss: 0.3203, Train Acc: 0.8684, \n",
      "Epoch [2160/10000], Loss: 0.3199, Train Acc: 0.8686, \n",
      "Epoch [2170/10000], Loss: 0.3195, Train Acc: 0.8689, \n",
      "Epoch [2180/10000], Loss: 0.3191, Train Acc: 0.8691, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██████                     | 2251/10000 [00:05<00:17, 449.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2190/10000], Loss: 0.3187, Train Acc: 0.8693, \n",
      "Epoch [2200/10000], Loss: 0.3183, Train Acc: 0.8694, \n",
      "Epoch [2210/10000], Loss: 0.3179, Train Acc: 0.8698, \n",
      "Epoch [2220/10000], Loss: 0.3175, Train Acc: 0.8700, \n",
      "Epoch [2230/10000], Loss: 0.3172, Train Acc: 0.8701, \n",
      "Epoch [2240/10000], Loss: 0.3168, Train Acc: 0.8702, \n",
      "Epoch [2250/10000], Loss: 0.3164, Train Acc: 0.8705, \n",
      "Epoch [2260/10000], Loss: 0.3160, Train Acc: 0.8709, \n",
      "Epoch [2270/10000], Loss: 0.3156, Train Acc: 0.8710, \n",
      "Epoch [2280/10000], Loss: 0.3153, Train Acc: 0.8713, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██████▎                    | 2347/10000 [00:06<00:16, 452.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2290/10000], Loss: 0.3149, Train Acc: 0.8717, \n",
      "Epoch [2300/10000], Loss: 0.3145, Train Acc: 0.8720, \n",
      "Epoch [2310/10000], Loss: 0.3142, Train Acc: 0.8721, \n",
      "Epoch [2320/10000], Loss: 0.3138, Train Acc: 0.8724, \n",
      "Epoch [2330/10000], Loss: 0.3134, Train Acc: 0.8726, \n",
      "Epoch [2340/10000], Loss: 0.3131, Train Acc: 0.8727, \n",
      "Epoch [2350/10000], Loss: 0.3127, Train Acc: 0.8730, \n",
      "Epoch [2360/10000], Loss: 0.3123, Train Acc: 0.8732, \n",
      "Epoch [2370/10000], Loss: 0.3120, Train Acc: 0.8736, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██████▌                    | 2447/10000 [00:06<00:15, 473.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2380/10000], Loss: 0.3116, Train Acc: 0.8740, \n",
      "Epoch [2390/10000], Loss: 0.3113, Train Acc: 0.8742, \n",
      "Epoch [2400/10000], Loss: 0.3109, Train Acc: 0.8745, \n",
      "Epoch [2410/10000], Loss: 0.3106, Train Acc: 0.8747, \n",
      "Epoch [2420/10000], Loss: 0.3102, Train Acc: 0.8750, \n",
      "Epoch [2430/10000], Loss: 0.3099, Train Acc: 0.8753, \n",
      "Epoch [2440/10000], Loss: 0.3095, Train Acc: 0.8756, \n",
      "Epoch [2450/10000], Loss: 0.3092, Train Acc: 0.8760, \n",
      "Epoch [2460/10000], Loss: 0.3088, Train Acc: 0.8762, \n",
      "Epoch [2470/10000], Loss: 0.3085, Train Acc: 0.8766, \n",
      "Epoch [2480/10000], Loss: 0.3081, Train Acc: 0.8769, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██████▊                    | 2546/10000 [00:06<00:15, 470.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2490/10000], Loss: 0.3078, Train Acc: 0.8770, \n",
      "Epoch [2500/10000], Loss: 0.3075, Train Acc: 0.8773, \n",
      "Epoch [2510/10000], Loss: 0.3071, Train Acc: 0.8778, \n",
      "Epoch [2520/10000], Loss: 0.3068, Train Acc: 0.8780, \n",
      "Epoch [2530/10000], Loss: 0.3064, Train Acc: 0.8782, \n",
      "Epoch [2540/10000], Loss: 0.3061, Train Acc: 0.8784, \n",
      "Epoch [2550/10000], Loss: 0.3058, Train Acc: 0.8788, \n",
      "Epoch [2560/10000], Loss: 0.3054, Train Acc: 0.8790, \n",
      "Epoch [2570/10000], Loss: 0.3051, Train Acc: 0.8792, \n",
      "Epoch [2580/10000], Loss: 0.3048, Train Acc: 0.8795, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|███████▏                   | 2646/10000 [00:06<00:15, 480.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2590/10000], Loss: 0.3044, Train Acc: 0.8796, \n",
      "Epoch [2600/10000], Loss: 0.3041, Train Acc: 0.8799, \n",
      "Epoch [2610/10000], Loss: 0.3038, Train Acc: 0.8801, \n",
      "Epoch [2620/10000], Loss: 0.3034, Train Acc: 0.8803, \n",
      "Epoch [2630/10000], Loss: 0.3031, Train Acc: 0.8805, \n",
      "Epoch [2640/10000], Loss: 0.3028, Train Acc: 0.8809, \n",
      "Epoch [2650/10000], Loss: 0.3025, Train Acc: 0.8811, \n",
      "Epoch [2660/10000], Loss: 0.3021, Train Acc: 0.8813, \n",
      "Epoch [2670/10000], Loss: 0.3018, Train Acc: 0.8815, \n",
      "Epoch [2680/10000], Loss: 0.3015, Train Acc: 0.8816, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|███████▍                   | 2745/10000 [00:06<00:15, 479.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2690/10000], Loss: 0.3012, Train Acc: 0.8817, \n",
      "Epoch [2700/10000], Loss: 0.3009, Train Acc: 0.8820, \n",
      "Epoch [2710/10000], Loss: 0.3005, Train Acc: 0.8822, \n",
      "Epoch [2720/10000], Loss: 0.3002, Train Acc: 0.8825, \n",
      "Epoch [2730/10000], Loss: 0.2999, Train Acc: 0.8827, \n",
      "Epoch [2740/10000], Loss: 0.2996, Train Acc: 0.8828, \n",
      "Epoch [2750/10000], Loss: 0.2993, Train Acc: 0.8830, \n",
      "Epoch [2760/10000], Loss: 0.2990, Train Acc: 0.8832, \n",
      "Epoch [2770/10000], Loss: 0.2987, Train Acc: 0.8834, \n",
      "Epoch [2780/10000], Loss: 0.2983, Train Acc: 0.8837, \n",
      "Epoch [2790/10000], Loss: 0.2980, Train Acc: 0.8838, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|███████▋                   | 2843/10000 [00:07<00:15, 454.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2800/10000], Loss: 0.2977, Train Acc: 0.8840, \n",
      "Epoch [2810/10000], Loss: 0.2974, Train Acc: 0.8841, \n",
      "Epoch [2820/10000], Loss: 0.2971, Train Acc: 0.8844, \n",
      "Epoch [2830/10000], Loss: 0.2968, Train Acc: 0.8846, \n",
      "Epoch [2840/10000], Loss: 0.2965, Train Acc: 0.8848, \n",
      "Epoch [2850/10000], Loss: 0.2962, Train Acc: 0.8850, \n",
      "Epoch [2860/10000], Loss: 0.2959, Train Acc: 0.8852, \n",
      "Epoch [2870/10000], Loss: 0.2956, Train Acc: 0.8854, \n",
      "Epoch [2880/10000], Loss: 0.2953, Train Acc: 0.8855, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|███████▉                   | 2934/10000 [00:07<00:17, 397.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2890/10000], Loss: 0.2950, Train Acc: 0.8857, \n",
      "Epoch [2900/10000], Loss: 0.2947, Train Acc: 0.8858, \n",
      "Epoch [2910/10000], Loss: 0.2944, Train Acc: 0.8861, \n",
      "Epoch [2920/10000], Loss: 0.2941, Train Acc: 0.8862, \n",
      "Epoch [2930/10000], Loss: 0.2938, Train Acc: 0.8864, \n",
      "Epoch [2940/10000], Loss: 0.2935, Train Acc: 0.8866, \n",
      "Epoch [2950/10000], Loss: 0.2932, Train Acc: 0.8869, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|████████▏                  | 3015/10000 [00:07<00:18, 374.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2960/10000], Loss: 0.2929, Train Acc: 0.8870, \n",
      "Epoch [2970/10000], Loss: 0.2926, Train Acc: 0.8872, \n",
      "Epoch [2980/10000], Loss: 0.2923, Train Acc: 0.8873, \n",
      "Epoch [2990/10000], Loss: 0.2920, Train Acc: 0.8877, \n",
      "Epoch [3000/10000], Loss: 0.2917, Train Acc: 0.8882, \n",
      "Epoch [3010/10000], Loss: 0.2914, Train Acc: 0.8885, \n",
      "Epoch [3020/10000], Loss: 0.2911, Train Acc: 0.8888, \n",
      "Epoch [3030/10000], Loss: 0.2908, Train Acc: 0.8892, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  31%|████████▎                  | 3091/10000 [00:07<00:19, 358.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3040/10000], Loss: 0.2905, Train Acc: 0.8893, \n",
      "Epoch [3050/10000], Loss: 0.2902, Train Acc: 0.8895, \n",
      "Epoch [3060/10000], Loss: 0.2899, Train Acc: 0.8898, \n",
      "Epoch [3070/10000], Loss: 0.2896, Train Acc: 0.8901, \n",
      "Epoch [3080/10000], Loss: 0.2894, Train Acc: 0.8903, \n",
      "Epoch [3090/10000], Loss: 0.2891, Train Acc: 0.8904, \n",
      "Epoch [3100/10000], Loss: 0.2888, Train Acc: 0.8907, \n",
      "Epoch [3110/10000], Loss: 0.2885, Train Acc: 0.8909, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|████████▌                  | 3177/10000 [00:07<00:17, 389.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3120/10000], Loss: 0.2882, Train Acc: 0.8911, \n",
      "Epoch [3130/10000], Loss: 0.2879, Train Acc: 0.8914, \n",
      "Epoch [3140/10000], Loss: 0.2876, Train Acc: 0.8915, \n",
      "Epoch [3150/10000], Loss: 0.2873, Train Acc: 0.8918, \n",
      "Epoch [3160/10000], Loss: 0.2871, Train Acc: 0.8920, \n",
      "Epoch [3170/10000], Loss: 0.2868, Train Acc: 0.8921, \n",
      "Epoch [3180/10000], Loss: 0.2865, Train Acc: 0.8922, \n",
      "Epoch [3190/10000], Loss: 0.2862, Train Acc: 0.8924, \n",
      "Epoch [3200/10000], Loss: 0.2859, Train Acc: 0.8927, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|████████▊                  | 3273/10000 [00:08<00:15, 433.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3210/10000], Loss: 0.2857, Train Acc: 0.8929, \n",
      "Epoch [3220/10000], Loss: 0.2854, Train Acc: 0.8932, \n",
      "Epoch [3230/10000], Loss: 0.2851, Train Acc: 0.8934, \n",
      "Epoch [3240/10000], Loss: 0.2848, Train Acc: 0.8938, \n",
      "Epoch [3250/10000], Loss: 0.2845, Train Acc: 0.8940, \n",
      "Epoch [3260/10000], Loss: 0.2843, Train Acc: 0.8942, \n",
      "Epoch [3270/10000], Loss: 0.2840, Train Acc: 0.8944, \n",
      "Epoch [3280/10000], Loss: 0.2837, Train Acc: 0.8948, \n",
      "Epoch [3290/10000], Loss: 0.2834, Train Acc: 0.8950, \n",
      "Epoch [3300/10000], Loss: 0.2831, Train Acc: 0.8953, \n",
      "Epoch [3310/10000], Loss: 0.2829, Train Acc: 0.8955, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  34%|█████████                  | 3377/10000 [00:08<00:13, 474.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3320/10000], Loss: 0.2826, Train Acc: 0.8957, \n",
      "Epoch [3330/10000], Loss: 0.2823, Train Acc: 0.8961, \n",
      "Epoch [3340/10000], Loss: 0.2820, Train Acc: 0.8965, \n",
      "Epoch [3350/10000], Loss: 0.2818, Train Acc: 0.8967, \n",
      "Epoch [3360/10000], Loss: 0.2815, Train Acc: 0.8969, \n",
      "Epoch [3370/10000], Loss: 0.2812, Train Acc: 0.8971, \n",
      "Epoch [3380/10000], Loss: 0.2810, Train Acc: 0.8973, \n",
      "Epoch [3390/10000], Loss: 0.2807, Train Acc: 0.8974, \n",
      "Epoch [3400/10000], Loss: 0.2804, Train Acc: 0.8978, \n",
      "Epoch [3410/10000], Loss: 0.2801, Train Acc: 0.8981, \n",
      "Epoch [3420/10000], Loss: 0.2799, Train Acc: 0.8982, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|█████████▌                 | 3532/10000 [00:08<00:12, 498.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3430/10000], Loss: 0.2796, Train Acc: 0.8985, \n",
      "Epoch [3440/10000], Loss: 0.2793, Train Acc: 0.8987, \n",
      "Epoch [3450/10000], Loss: 0.2791, Train Acc: 0.8989, \n",
      "Epoch [3460/10000], Loss: 0.2788, Train Acc: 0.8992, \n",
      "Epoch [3470/10000], Loss: 0.2785, Train Acc: 0.8995, \n",
      "Epoch [3480/10000], Loss: 0.2783, Train Acc: 0.8998, \n",
      "Epoch [3490/10000], Loss: 0.2780, Train Acc: 0.9000, \n",
      "Epoch [3500/10000], Loss: 0.2777, Train Acc: 0.9002, \n",
      "Epoch [3510/10000], Loss: 0.2775, Train Acc: 0.9003, \n",
      "Epoch [3520/10000], Loss: 0.2772, Train Acc: 0.9006, \n",
      "Epoch [3530/10000], Loss: 0.2769, Train Acc: 0.9008, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|█████████▊                 | 3633/10000 [00:08<00:13, 489.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3540/10000], Loss: 0.2767, Train Acc: 0.9010, \n",
      "Epoch [3550/10000], Loss: 0.2764, Train Acc: 0.9013, \n",
      "Epoch [3560/10000], Loss: 0.2761, Train Acc: 0.9015, \n",
      "Epoch [3570/10000], Loss: 0.2759, Train Acc: 0.9018, \n",
      "Epoch [3580/10000], Loss: 0.2756, Train Acc: 0.9021, \n",
      "Epoch [3590/10000], Loss: 0.2753, Train Acc: 0.9024, \n",
      "Epoch [3600/10000], Loss: 0.2751, Train Acc: 0.9028, \n",
      "Epoch [3610/10000], Loss: 0.2748, Train Acc: 0.9030, \n",
      "Epoch [3620/10000], Loss: 0.2746, Train Acc: 0.9034, \n",
      "Epoch [3630/10000], Loss: 0.2743, Train Acc: 0.9039, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  37%|██████████                 | 3735/10000 [00:09<00:12, 494.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3640/10000], Loss: 0.2740, Train Acc: 0.9042, \n",
      "Epoch [3650/10000], Loss: 0.2738, Train Acc: 0.9045, \n",
      "Epoch [3660/10000], Loss: 0.2735, Train Acc: 0.9048, \n",
      "Epoch [3670/10000], Loss: 0.2733, Train Acc: 0.9051, \n",
      "Epoch [3680/10000], Loss: 0.2730, Train Acc: 0.9054, \n",
      "Epoch [3690/10000], Loss: 0.2727, Train Acc: 0.9056, \n",
      "Epoch [3700/10000], Loss: 0.2725, Train Acc: 0.9059, \n",
      "Epoch [3710/10000], Loss: 0.2722, Train Acc: 0.9061, \n",
      "Epoch [3720/10000], Loss: 0.2720, Train Acc: 0.9063, \n",
      "Epoch [3730/10000], Loss: 0.2717, Train Acc: 0.9065, \n",
      "Epoch [3740/10000], Loss: 0.2715, Train Acc: 0.9069, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|██████████▎                | 3835/10000 [00:09<00:12, 484.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3750/10000], Loss: 0.2712, Train Acc: 0.9070, \n",
      "Epoch [3760/10000], Loss: 0.2709, Train Acc: 0.9073, \n",
      "Epoch [3770/10000], Loss: 0.2707, Train Acc: 0.9074, \n",
      "Epoch [3780/10000], Loss: 0.2704, Train Acc: 0.9076, \n",
      "Epoch [3790/10000], Loss: 0.2702, Train Acc: 0.9078, \n",
      "Epoch [3800/10000], Loss: 0.2699, Train Acc: 0.9082, \n",
      "Epoch [3810/10000], Loss: 0.2697, Train Acc: 0.9084, \n",
      "Epoch [3820/10000], Loss: 0.2694, Train Acc: 0.9086, \n",
      "Epoch [3830/10000], Loss: 0.2692, Train Acc: 0.9087, \n",
      "Epoch [3840/10000], Loss: 0.2689, Train Acc: 0.9089, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|██████████▍                | 3884/10000 [00:09<00:12, 470.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3850/10000], Loss: 0.2687, Train Acc: 0.9090, \n",
      "Epoch [3860/10000], Loss: 0.2684, Train Acc: 0.9093, \n",
      "Epoch [3870/10000], Loss: 0.2682, Train Acc: 0.9094, \n",
      "Epoch [3880/10000], Loss: 0.2679, Train Acc: 0.9096, \n",
      "Epoch [3890/10000], Loss: 0.2676, Train Acc: 0.9099, \n",
      "Epoch [3900/10000], Loss: 0.2674, Train Acc: 0.9100, \n",
      "Epoch [3910/10000], Loss: 0.2671, Train Acc: 0.9101, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|██████████▋                | 3974/10000 [00:09<00:14, 403.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3920/10000], Loss: 0.2669, Train Acc: 0.9104, \n",
      "Epoch [3930/10000], Loss: 0.2666, Train Acc: 0.9105, \n",
      "Epoch [3940/10000], Loss: 0.2664, Train Acc: 0.9107, \n",
      "Epoch [3950/10000], Loss: 0.2662, Train Acc: 0.9109, \n",
      "Epoch [3960/10000], Loss: 0.2659, Train Acc: 0.9111, \n",
      "Epoch [3970/10000], Loss: 0.2657, Train Acc: 0.9113, \n",
      "Epoch [3980/10000], Loss: 0.2654, Train Acc: 0.9116, \n",
      "Epoch [3990/10000], Loss: 0.2652, Train Acc: 0.9118, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|██████████▉                | 4061/10000 [00:09<00:14, 408.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4000/10000], Loss: 0.2649, Train Acc: 0.9121, \n",
      "Epoch [4010/10000], Loss: 0.2647, Train Acc: 0.9122, \n",
      "Epoch [4020/10000], Loss: 0.2644, Train Acc: 0.9125, \n",
      "Epoch [4030/10000], Loss: 0.2642, Train Acc: 0.9125, \n",
      "Epoch [4040/10000], Loss: 0.2639, Train Acc: 0.9128, \n",
      "Epoch [4050/10000], Loss: 0.2637, Train Acc: 0.9129, \n",
      "Epoch [4060/10000], Loss: 0.2634, Train Acc: 0.9130, \n",
      "Epoch [4070/10000], Loss: 0.2632, Train Acc: 0.9133, \n",
      "Epoch [4080/10000], Loss: 0.2629, Train Acc: 0.9134, \n",
      "Epoch [4090/10000], Loss: 0.2627, Train Acc: 0.9137, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|███████████▏               | 4161/10000 [00:10<00:12, 452.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4100/10000], Loss: 0.2625, Train Acc: 0.9138, \n",
      "Epoch [4110/10000], Loss: 0.2622, Train Acc: 0.9140, \n",
      "Epoch [4120/10000], Loss: 0.2620, Train Acc: 0.9142, \n",
      "Epoch [4130/10000], Loss: 0.2617, Train Acc: 0.9143, \n",
      "Epoch [4140/10000], Loss: 0.2615, Train Acc: 0.9146, \n",
      "Epoch [4150/10000], Loss: 0.2613, Train Acc: 0.9148, \n",
      "Epoch [4160/10000], Loss: 0.2610, Train Acc: 0.9149, \n",
      "Epoch [4170/10000], Loss: 0.2608, Train Acc: 0.9151, \n",
      "Epoch [4180/10000], Loss: 0.2605, Train Acc: 0.9154, \n",
      "Epoch [4190/10000], Loss: 0.2603, Train Acc: 0.9155, \n",
      "Epoch [4200/10000], Loss: 0.2600, Train Acc: 0.9157, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|███████████▍               | 4256/10000 [00:10<00:12, 450.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4210/10000], Loss: 0.2598, Train Acc: 0.9159, \n",
      "Epoch [4220/10000], Loss: 0.2596, Train Acc: 0.9160, \n",
      "Epoch [4230/10000], Loss: 0.2593, Train Acc: 0.9163, \n",
      "Epoch [4240/10000], Loss: 0.2591, Train Acc: 0.9164, \n",
      "Epoch [4250/10000], Loss: 0.2589, Train Acc: 0.9165, \n",
      "Epoch [4260/10000], Loss: 0.2586, Train Acc: 0.9167, \n",
      "Epoch [4270/10000], Loss: 0.2584, Train Acc: 0.9168, \n",
      "Epoch [4280/10000], Loss: 0.2581, Train Acc: 0.9171, \n",
      "Epoch [4290/10000], Loss: 0.2579, Train Acc: 0.9171, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|███████████▊               | 4354/10000 [00:10<00:12, 465.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4300/10000], Loss: 0.2577, Train Acc: 0.9172, \n",
      "Epoch [4310/10000], Loss: 0.2574, Train Acc: 0.9175, \n",
      "Epoch [4320/10000], Loss: 0.2572, Train Acc: 0.9176, \n",
      "Epoch [4330/10000], Loss: 0.2570, Train Acc: 0.9179, \n",
      "Epoch [4340/10000], Loss: 0.2567, Train Acc: 0.9181, \n",
      "Epoch [4350/10000], Loss: 0.2565, Train Acc: 0.9183, \n",
      "Epoch [4360/10000], Loss: 0.2562, Train Acc: 0.9184, \n",
      "Epoch [4370/10000], Loss: 0.2560, Train Acc: 0.9186, \n",
      "Epoch [4380/10000], Loss: 0.2558, Train Acc: 0.9187, \n",
      "Epoch [4390/10000], Loss: 0.2555, Train Acc: 0.9190, \n",
      "Epoch [4400/10000], Loss: 0.2553, Train Acc: 0.9193, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|████████████▏              | 4505/10000 [00:10<00:11, 481.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4410/10000], Loss: 0.2551, Train Acc: 0.9194, \n",
      "Epoch [4420/10000], Loss: 0.2548, Train Acc: 0.9196, \n",
      "Epoch [4430/10000], Loss: 0.2546, Train Acc: 0.9197, \n",
      "Epoch [4440/10000], Loss: 0.2544, Train Acc: 0.9199, \n",
      "Epoch [4450/10000], Loss: 0.2541, Train Acc: 0.9201, \n",
      "Epoch [4460/10000], Loss: 0.2539, Train Acc: 0.9202, \n",
      "Epoch [4470/10000], Loss: 0.2537, Train Acc: 0.9204, \n",
      "Epoch [4480/10000], Loss: 0.2535, Train Acc: 0.9206, \n",
      "Epoch [4490/10000], Loss: 0.2532, Train Acc: 0.9209, \n",
      "Epoch [4500/10000], Loss: 0.2530, Train Acc: 0.9210, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|████████████▍              | 4609/10000 [00:11<00:10, 497.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4510/10000], Loss: 0.2528, Train Acc: 0.9213, \n",
      "Epoch [4520/10000], Loss: 0.2525, Train Acc: 0.9217, \n",
      "Epoch [4530/10000], Loss: 0.2523, Train Acc: 0.9218, \n",
      "Epoch [4540/10000], Loss: 0.2521, Train Acc: 0.9219, \n",
      "Epoch [4550/10000], Loss: 0.2518, Train Acc: 0.9221, \n",
      "Epoch [4560/10000], Loss: 0.2516, Train Acc: 0.9224, \n",
      "Epoch [4570/10000], Loss: 0.2514, Train Acc: 0.9227, \n",
      "Epoch [4580/10000], Loss: 0.2512, Train Acc: 0.9229, \n",
      "Epoch [4590/10000], Loss: 0.2509, Train Acc: 0.9230, \n",
      "Epoch [4600/10000], Loss: 0.2507, Train Acc: 0.9232, \n",
      "Epoch [4610/10000], Loss: 0.2505, Train Acc: 0.9234, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|████████████▌              | 4659/10000 [00:11<00:11, 470.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4620/10000], Loss: 0.2503, Train Acc: 0.9236, \n",
      "Epoch [4630/10000], Loss: 0.2500, Train Acc: 0.9238, \n",
      "Epoch [4640/10000], Loss: 0.2498, Train Acc: 0.9240, \n",
      "Epoch [4650/10000], Loss: 0.2496, Train Acc: 0.9243, \n",
      "Epoch [4660/10000], Loss: 0.2493, Train Acc: 0.9244, \n",
      "Epoch [4670/10000], Loss: 0.2491, Train Acc: 0.9247, \n",
      "Epoch [4680/10000], Loss: 0.2489, Train Acc: 0.9248, \n",
      "Epoch [4690/10000], Loss: 0.2487, Train Acc: 0.9250, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|████████████▊              | 4751/10000 [00:11<00:13, 401.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4700/10000], Loss: 0.2484, Train Acc: 0.9252, \n",
      "Epoch [4710/10000], Loss: 0.2482, Train Acc: 0.9258, \n",
      "Epoch [4720/10000], Loss: 0.2480, Train Acc: 0.9260, \n",
      "Epoch [4730/10000], Loss: 0.2478, Train Acc: 0.9262, \n",
      "Epoch [4740/10000], Loss: 0.2476, Train Acc: 0.9265, \n",
      "Epoch [4750/10000], Loss: 0.2473, Train Acc: 0.9267, \n",
      "Epoch [4760/10000], Loss: 0.2471, Train Acc: 0.9270, \n",
      "Epoch [4770/10000], Loss: 0.2469, Train Acc: 0.9270, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|█████████████              | 4848/10000 [00:11<00:11, 437.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4780/10000], Loss: 0.2467, Train Acc: 0.9274, \n",
      "Epoch [4790/10000], Loss: 0.2464, Train Acc: 0.9275, \n",
      "Epoch [4800/10000], Loss: 0.2462, Train Acc: 0.9277, \n",
      "Epoch [4810/10000], Loss: 0.2460, Train Acc: 0.9278, \n",
      "Epoch [4820/10000], Loss: 0.2458, Train Acc: 0.9280, \n",
      "Epoch [4830/10000], Loss: 0.2456, Train Acc: 0.9281, \n",
      "Epoch [4840/10000], Loss: 0.2453, Train Acc: 0.9283, \n",
      "Epoch [4850/10000], Loss: 0.2451, Train Acc: 0.9285, \n",
      "Epoch [4860/10000], Loss: 0.2449, Train Acc: 0.9287, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|█████████████▏             | 4893/10000 [00:11<00:12, 418.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4870/10000], Loss: 0.2447, Train Acc: 0.9288, \n",
      "Epoch [4880/10000], Loss: 0.2445, Train Acc: 0.9290, \n",
      "Epoch [4890/10000], Loss: 0.2442, Train Acc: 0.9292, \n",
      "Epoch [4900/10000], Loss: 0.2440, Train Acc: 0.9293, \n",
      "Epoch [4910/10000], Loss: 0.2438, Train Acc: 0.9295, \n",
      "Epoch [4920/10000], Loss: 0.2436, Train Acc: 0.9296, \n",
      "Epoch [4930/10000], Loss: 0.2434, Train Acc: 0.9297, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████████████▌             | 5009/10000 [00:12<00:14, 336.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4940/10000], Loss: 0.2432, Train Acc: 0.9298, \n",
      "Epoch [4950/10000], Loss: 0.2429, Train Acc: 0.9299, \n",
      "Epoch [4960/10000], Loss: 0.2427, Train Acc: 0.9301, \n",
      "Epoch [4970/10000], Loss: 0.2425, Train Acc: 0.9303, \n",
      "Epoch [4980/10000], Loss: 0.2423, Train Acc: 0.9304, \n",
      "Epoch [4990/10000], Loss: 0.2421, Train Acc: 0.9307, \n",
      "Epoch [5000/10000], Loss: 0.2419, Train Acc: 0.9308, \n",
      "Epoch [5010/10000], Loss: 0.2416, Train Acc: 0.9310, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  51%|█████████████▊             | 5108/10000 [00:12<00:12, 407.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5020/10000], Loss: 0.2414, Train Acc: 0.9310, \n",
      "Epoch [5030/10000], Loss: 0.2412, Train Acc: 0.9311, \n",
      "Epoch [5040/10000], Loss: 0.2410, Train Acc: 0.9313, \n",
      "Epoch [5050/10000], Loss: 0.2408, Train Acc: 0.9316, \n",
      "Epoch [5060/10000], Loss: 0.2406, Train Acc: 0.9317, \n",
      "Epoch [5070/10000], Loss: 0.2404, Train Acc: 0.9318, \n",
      "Epoch [5080/10000], Loss: 0.2401, Train Acc: 0.9319, \n",
      "Epoch [5090/10000], Loss: 0.2399, Train Acc: 0.9320, \n",
      "Epoch [5100/10000], Loss: 0.2397, Train Acc: 0.9321, \n",
      "Epoch [5110/10000], Loss: 0.2395, Train Acc: 0.9322, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|██████████████             | 5208/10000 [00:12<00:10, 449.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5120/10000], Loss: 0.2393, Train Acc: 0.9324, \n",
      "Epoch [5130/10000], Loss: 0.2391, Train Acc: 0.9325, \n",
      "Epoch [5140/10000], Loss: 0.2389, Train Acc: 0.9326, \n",
      "Epoch [5150/10000], Loss: 0.2387, Train Acc: 0.9327, \n",
      "Epoch [5160/10000], Loss: 0.2384, Train Acc: 0.9328, \n",
      "Epoch [5170/10000], Loss: 0.2382, Train Acc: 0.9330, \n",
      "Epoch [5180/10000], Loss: 0.2380, Train Acc: 0.9331, \n",
      "Epoch [5190/10000], Loss: 0.2378, Train Acc: 0.9332, \n",
      "Epoch [5200/10000], Loss: 0.2376, Train Acc: 0.9333, \n",
      "Epoch [5210/10000], Loss: 0.2374, Train Acc: 0.9334, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  53%|██████████████▏            | 5259/10000 [00:12<00:10, 464.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5220/10000], Loss: 0.2372, Train Acc: 0.9335, \n",
      "Epoch [5230/10000], Loss: 0.2370, Train Acc: 0.9337, \n",
      "Epoch [5240/10000], Loss: 0.2368, Train Acc: 0.9338, \n",
      "Epoch [5250/10000], Loss: 0.2366, Train Acc: 0.9339, \n",
      "Epoch [5260/10000], Loss: 0.2364, Train Acc: 0.9340, \n",
      "Epoch [5270/10000], Loss: 0.2361, Train Acc: 0.9342, \n",
      "Epoch [5280/10000], Loss: 0.2359, Train Acc: 0.9343, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  53%|██████████████▍            | 5349/10000 [00:12<00:11, 390.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5290/10000], Loss: 0.2357, Train Acc: 0.9345, \n",
      "Epoch [5300/10000], Loss: 0.2355, Train Acc: 0.9345, \n",
      "Epoch [5310/10000], Loss: 0.2353, Train Acc: 0.9346, \n",
      "Epoch [5320/10000], Loss: 0.2351, Train Acc: 0.9347, \n",
      "Epoch [5330/10000], Loss: 0.2349, Train Acc: 0.9347, \n",
      "Epoch [5340/10000], Loss: 0.2347, Train Acc: 0.9348, \n",
      "Epoch [5350/10000], Loss: 0.2345, Train Acc: 0.9349, \n",
      "Epoch [5360/10000], Loss: 0.2343, Train Acc: 0.9349, \n",
      "Epoch [5370/10000], Loss: 0.2341, Train Acc: 0.9350, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|██████████████▋            | 5442/10000 [00:13<00:10, 424.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5380/10000], Loss: 0.2339, Train Acc: 0.9351, \n",
      "Epoch [5390/10000], Loss: 0.2337, Train Acc: 0.9352, \n",
      "Epoch [5400/10000], Loss: 0.2335, Train Acc: 0.9352, \n",
      "Epoch [5410/10000], Loss: 0.2333, Train Acc: 0.9353, \n",
      "Epoch [5420/10000], Loss: 0.2331, Train Acc: 0.9354, \n",
      "Epoch [5430/10000], Loss: 0.2329, Train Acc: 0.9355, \n",
      "Epoch [5440/10000], Loss: 0.2327, Train Acc: 0.9355, \n",
      "Epoch [5450/10000], Loss: 0.2325, Train Acc: 0.9356, \n",
      "Epoch [5460/10000], Loss: 0.2322, Train Acc: 0.9356, \n",
      "Epoch [5470/10000], Loss: 0.2320, Train Acc: 0.9357, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|██████████████▉            | 5546/10000 [00:13<00:09, 468.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5480/10000], Loss: 0.2318, Train Acc: 0.9358, \n",
      "Epoch [5490/10000], Loss: 0.2316, Train Acc: 0.9359, \n",
      "Epoch [5500/10000], Loss: 0.2314, Train Acc: 0.9360, \n",
      "Epoch [5510/10000], Loss: 0.2312, Train Acc: 0.9361, \n",
      "Epoch [5520/10000], Loss: 0.2310, Train Acc: 0.9363, \n",
      "Epoch [5530/10000], Loss: 0.2308, Train Acc: 0.9364, \n",
      "Epoch [5540/10000], Loss: 0.2306, Train Acc: 0.9365, \n",
      "Epoch [5550/10000], Loss: 0.2304, Train Acc: 0.9366, \n",
      "Epoch [5560/10000], Loss: 0.2302, Train Acc: 0.9366, \n",
      "Epoch [5570/10000], Loss: 0.2300, Train Acc: 0.9366, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|███████████████▏           | 5644/10000 [00:13<00:09, 462.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5580/10000], Loss: 0.2298, Train Acc: 0.9366, \n",
      "Epoch [5590/10000], Loss: 0.2296, Train Acc: 0.9368, \n",
      "Epoch [5600/10000], Loss: 0.2294, Train Acc: 0.9368, \n",
      "Epoch [5610/10000], Loss: 0.2292, Train Acc: 0.9370, \n",
      "Epoch [5620/10000], Loss: 0.2290, Train Acc: 0.9371, \n",
      "Epoch [5630/10000], Loss: 0.2288, Train Acc: 0.9372, \n",
      "Epoch [5640/10000], Loss: 0.2286, Train Acc: 0.9374, \n",
      "Epoch [5650/10000], Loss: 0.2285, Train Acc: 0.9375, \n",
      "Epoch [5660/10000], Loss: 0.2283, Train Acc: 0.9376, \n",
      "Epoch [5670/10000], Loss: 0.2281, Train Acc: 0.9377, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|███████████████▌           | 5742/10000 [00:13<00:08, 474.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5680/10000], Loss: 0.2279, Train Acc: 0.9379, \n",
      "Epoch [5690/10000], Loss: 0.2277, Train Acc: 0.9380, \n",
      "Epoch [5700/10000], Loss: 0.2275, Train Acc: 0.9382, \n",
      "Epoch [5710/10000], Loss: 0.2273, Train Acc: 0.9383, \n",
      "Epoch [5720/10000], Loss: 0.2271, Train Acc: 0.9384, \n",
      "Epoch [5730/10000], Loss: 0.2269, Train Acc: 0.9386, \n",
      "Epoch [5740/10000], Loss: 0.2267, Train Acc: 0.9388, \n",
      "Epoch [5750/10000], Loss: 0.2265, Train Acc: 0.9389, \n",
      "Epoch [5760/10000], Loss: 0.2263, Train Acc: 0.9390, \n",
      "Epoch [5770/10000], Loss: 0.2261, Train Acc: 0.9393, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|███████████████▊           | 5841/10000 [00:13<00:08, 485.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5780/10000], Loss: 0.2259, Train Acc: 0.9394, \n",
      "Epoch [5790/10000], Loss: 0.2257, Train Acc: 0.9398, \n",
      "Epoch [5800/10000], Loss: 0.2255, Train Acc: 0.9400, \n",
      "Epoch [5810/10000], Loss: 0.2253, Train Acc: 0.9401, \n",
      "Epoch [5820/10000], Loss: 0.2251, Train Acc: 0.9402, \n",
      "Epoch [5830/10000], Loss: 0.2249, Train Acc: 0.9403, \n",
      "Epoch [5840/10000], Loss: 0.2247, Train Acc: 0.9406, \n",
      "Epoch [5850/10000], Loss: 0.2246, Train Acc: 0.9408, \n",
      "Epoch [5860/10000], Loss: 0.2244, Train Acc: 0.9411, \n",
      "Epoch [5870/10000], Loss: 0.2242, Train Acc: 0.9411, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|████████████████           | 5941/10000 [00:14<00:08, 491.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5880/10000], Loss: 0.2240, Train Acc: 0.9414, \n",
      "Epoch [5890/10000], Loss: 0.2238, Train Acc: 0.9416, \n",
      "Epoch [5900/10000], Loss: 0.2236, Train Acc: 0.9418, \n",
      "Epoch [5910/10000], Loss: 0.2234, Train Acc: 0.9421, \n",
      "Epoch [5920/10000], Loss: 0.2232, Train Acc: 0.9423, \n",
      "Epoch [5930/10000], Loss: 0.2230, Train Acc: 0.9425, \n",
      "Epoch [5940/10000], Loss: 0.2228, Train Acc: 0.9429, \n",
      "Epoch [5950/10000], Loss: 0.2226, Train Acc: 0.9431, \n",
      "Epoch [5960/10000], Loss: 0.2225, Train Acc: 0.9435, \n",
      "Epoch [5970/10000], Loss: 0.2223, Train Acc: 0.9437, \n",
      "Epoch [5980/10000], Loss: 0.2221, Train Acc: 0.9439, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|████████████████▎          | 6042/10000 [00:14<00:07, 496.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5990/10000], Loss: 0.2219, Train Acc: 0.9441, \n",
      "Epoch [6000/10000], Loss: 0.2217, Train Acc: 0.9444, \n",
      "Epoch [6010/10000], Loss: 0.2215, Train Acc: 0.9446, \n",
      "Epoch [6020/10000], Loss: 0.2213, Train Acc: 0.9448, \n",
      "Epoch [6030/10000], Loss: 0.2211, Train Acc: 0.9451, \n",
      "Epoch [6040/10000], Loss: 0.2210, Train Acc: 0.9453, \n",
      "Epoch [6050/10000], Loss: 0.2208, Train Acc: 0.9454, \n",
      "Epoch [6060/10000], Loss: 0.2206, Train Acc: 0.9455, \n",
      "Epoch [6070/10000], Loss: 0.2204, Train Acc: 0.9456, \n",
      "Epoch [6080/10000], Loss: 0.2202, Train Acc: 0.9456, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|████████████████▌          | 6140/10000 [00:14<00:08, 471.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6090/10000], Loss: 0.2200, Train Acc: 0.9459, \n",
      "Epoch [6100/10000], Loss: 0.2198, Train Acc: 0.9460, \n",
      "Epoch [6110/10000], Loss: 0.2196, Train Acc: 0.9461, \n",
      "Epoch [6120/10000], Loss: 0.2195, Train Acc: 0.9463, \n",
      "Epoch [6130/10000], Loss: 0.2193, Train Acc: 0.9463, \n",
      "Epoch [6140/10000], Loss: 0.2191, Train Acc: 0.9464, \n",
      "Epoch [6150/10000], Loss: 0.2189, Train Acc: 0.9466, \n",
      "Epoch [6160/10000], Loss: 0.2187, Train Acc: 0.9466, \n",
      "Epoch [6170/10000], Loss: 0.2185, Train Acc: 0.9467, \n",
      "Epoch [6180/10000], Loss: 0.2184, Train Acc: 0.9469, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|████████████████▊          | 6243/10000 [00:14<00:07, 490.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6190/10000], Loss: 0.2182, Train Acc: 0.9470, \n",
      "Epoch [6200/10000], Loss: 0.2180, Train Acc: 0.9471, \n",
      "Epoch [6210/10000], Loss: 0.2178, Train Acc: 0.9471, \n",
      "Epoch [6220/10000], Loss: 0.2176, Train Acc: 0.9472, \n",
      "Epoch [6230/10000], Loss: 0.2174, Train Acc: 0.9473, \n",
      "Epoch [6240/10000], Loss: 0.2173, Train Acc: 0.9474, \n",
      "Epoch [6250/10000], Loss: 0.2171, Train Acc: 0.9475, \n",
      "Epoch [6260/10000], Loss: 0.2169, Train Acc: 0.9476, \n",
      "Epoch [6270/10000], Loss: 0.2167, Train Acc: 0.9477, \n",
      "Epoch [6280/10000], Loss: 0.2165, Train Acc: 0.9478, \n",
      "Epoch [6290/10000], Loss: 0.2163, Train Acc: 0.9479, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  63%|████████████████▉          | 6296/10000 [00:14<00:07, 499.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6300/10000], Loss: 0.2162, Train Acc: 0.9481, \n",
      "Epoch [6310/10000], Loss: 0.2160, Train Acc: 0.9481, \n",
      "Epoch [6320/10000], Loss: 0.2158, Train Acc: 0.9482, \n",
      "Epoch [6330/10000], Loss: 0.2156, Train Acc: 0.9482, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|█████████████████▎         | 6394/10000 [00:15<00:09, 377.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6340/10000], Loss: 0.2154, Train Acc: 0.9482, \n",
      "Epoch [6350/10000], Loss: 0.2153, Train Acc: 0.9483, \n",
      "Epoch [6360/10000], Loss: 0.2151, Train Acc: 0.9483, \n",
      "Epoch [6370/10000], Loss: 0.2149, Train Acc: 0.9484, \n",
      "Epoch [6380/10000], Loss: 0.2147, Train Acc: 0.9485, \n",
      "Epoch [6390/10000], Loss: 0.2145, Train Acc: 0.9485, \n",
      "Epoch [6400/10000], Loss: 0.2144, Train Acc: 0.9485, \n",
      "Epoch [6410/10000], Loss: 0.2142, Train Acc: 0.9486, \n",
      "Epoch [6420/10000], Loss: 0.2140, Train Acc: 0.9486, \n",
      "Epoch [6430/10000], Loss: 0.2138, Train Acc: 0.9487, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|█████████████████▌         | 6485/10000 [00:15<00:08, 403.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6440/10000], Loss: 0.2136, Train Acc: 0.9487, \n",
      "Epoch [6450/10000], Loss: 0.2135, Train Acc: 0.9487, \n",
      "Epoch [6460/10000], Loss: 0.2133, Train Acc: 0.9490, \n",
      "Epoch [6470/10000], Loss: 0.2131, Train Acc: 0.9490, \n",
      "Epoch [6480/10000], Loss: 0.2129, Train Acc: 0.9490, \n",
      "Epoch [6490/10000], Loss: 0.2128, Train Acc: 0.9491, \n",
      "Epoch [6500/10000], Loss: 0.2126, Train Acc: 0.9491, \n",
      "Epoch [6510/10000], Loss: 0.2124, Train Acc: 0.9493, \n",
      "Epoch [6520/10000], Loss: 0.2122, Train Acc: 0.9494, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|█████████████████▊         | 6583/10000 [00:15<00:07, 442.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6530/10000], Loss: 0.2121, Train Acc: 0.9494, \n",
      "Epoch [6540/10000], Loss: 0.2119, Train Acc: 0.9494, \n",
      "Epoch [6550/10000], Loss: 0.2117, Train Acc: 0.9495, \n",
      "Epoch [6560/10000], Loss: 0.2115, Train Acc: 0.9496, \n",
      "Epoch [6570/10000], Loss: 0.2114, Train Acc: 0.9497, \n",
      "Epoch [6580/10000], Loss: 0.2112, Train Acc: 0.9498, \n",
      "Epoch [6590/10000], Loss: 0.2110, Train Acc: 0.9500, \n",
      "Epoch [6600/10000], Loss: 0.2108, Train Acc: 0.9502, \n",
      "Epoch [6610/10000], Loss: 0.2107, Train Acc: 0.9503, \n",
      "Epoch [6620/10000], Loss: 0.2105, Train Acc: 0.9503, \n",
      "Epoch [6630/10000], Loss: 0.2103, Train Acc: 0.9505, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|██████████████████▏        | 6737/10000 [00:15<00:06, 484.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6640/10000], Loss: 0.2101, Train Acc: 0.9507, \n",
      "Epoch [6650/10000], Loss: 0.2100, Train Acc: 0.9508, \n",
      "Epoch [6660/10000], Loss: 0.2098, Train Acc: 0.9509, \n",
      "Epoch [6670/10000], Loss: 0.2096, Train Acc: 0.9510, \n",
      "Epoch [6680/10000], Loss: 0.2094, Train Acc: 0.9511, \n",
      "Epoch [6690/10000], Loss: 0.2093, Train Acc: 0.9511, \n",
      "Epoch [6700/10000], Loss: 0.2091, Train Acc: 0.9513, \n",
      "Epoch [6710/10000], Loss: 0.2089, Train Acc: 0.9513, \n",
      "Epoch [6720/10000], Loss: 0.2088, Train Acc: 0.9514, \n",
      "Epoch [6730/10000], Loss: 0.2086, Train Acc: 0.9514, \n",
      "Epoch [6740/10000], Loss: 0.2084, Train Acc: 0.9515, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|██████████████████▍        | 6837/10000 [00:16<00:06, 481.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6750/10000], Loss: 0.2082, Train Acc: 0.9515, \n",
      "Epoch [6760/10000], Loss: 0.2081, Train Acc: 0.9517, \n",
      "Epoch [6770/10000], Loss: 0.2079, Train Acc: 0.9518, \n",
      "Epoch [6780/10000], Loss: 0.2077, Train Acc: 0.9519, \n",
      "Epoch [6790/10000], Loss: 0.2076, Train Acc: 0.9520, \n",
      "Epoch [6800/10000], Loss: 0.2074, Train Acc: 0.9521, \n",
      "Epoch [6810/10000], Loss: 0.2072, Train Acc: 0.9522, \n",
      "Epoch [6820/10000], Loss: 0.2071, Train Acc: 0.9523, \n",
      "Epoch [6830/10000], Loss: 0.2069, Train Acc: 0.9523, \n",
      "Epoch [6840/10000], Loss: 0.2067, Train Acc: 0.9523, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|██████████████████▋        | 6936/10000 [00:16<00:06, 482.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6850/10000], Loss: 0.2065, Train Acc: 0.9525, \n",
      "Epoch [6860/10000], Loss: 0.2064, Train Acc: 0.9526, \n",
      "Epoch [6870/10000], Loss: 0.2062, Train Acc: 0.9527, \n",
      "Epoch [6880/10000], Loss: 0.2060, Train Acc: 0.9527, \n",
      "Epoch [6890/10000], Loss: 0.2059, Train Acc: 0.9528, \n",
      "Epoch [6900/10000], Loss: 0.2057, Train Acc: 0.9529, \n",
      "Epoch [6910/10000], Loss: 0.2055, Train Acc: 0.9530, \n",
      "Epoch [6920/10000], Loss: 0.2054, Train Acc: 0.9531, \n",
      "Epoch [6930/10000], Loss: 0.2052, Train Acc: 0.9532, \n",
      "Epoch [6940/10000], Loss: 0.2050, Train Acc: 0.9533, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|██████████████████▉        | 7034/10000 [00:16<00:06, 480.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6950/10000], Loss: 0.2049, Train Acc: 0.9533, \n",
      "Epoch [6960/10000], Loss: 0.2047, Train Acc: 0.9533, \n",
      "Epoch [6970/10000], Loss: 0.2045, Train Acc: 0.9534, \n",
      "Epoch [6980/10000], Loss: 0.2044, Train Acc: 0.9534, \n",
      "Epoch [6990/10000], Loss: 0.2042, Train Acc: 0.9535, \n",
      "Epoch [7000/10000], Loss: 0.2040, Train Acc: 0.9536, \n",
      "Epoch [7010/10000], Loss: 0.2039, Train Acc: 0.9537, \n",
      "Epoch [7020/10000], Loss: 0.2037, Train Acc: 0.9537, \n",
      "Epoch [7030/10000], Loss: 0.2035, Train Acc: 0.9538, \n",
      "Epoch [7040/10000], Loss: 0.2034, Train Acc: 0.9539, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████████████████▎       | 7133/10000 [00:16<00:06, 466.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7050/10000], Loss: 0.2032, Train Acc: 0.9539, \n",
      "Epoch [7060/10000], Loss: 0.2031, Train Acc: 0.9540, \n",
      "Epoch [7070/10000], Loss: 0.2029, Train Acc: 0.9540, \n",
      "Epoch [7080/10000], Loss: 0.2027, Train Acc: 0.9541, \n",
      "Epoch [7090/10000], Loss: 0.2026, Train Acc: 0.9542, \n",
      "Epoch [7100/10000], Loss: 0.2024, Train Acc: 0.9543, \n",
      "Epoch [7110/10000], Loss: 0.2022, Train Acc: 0.9544, \n",
      "Epoch [7120/10000], Loss: 0.2021, Train Acc: 0.9544, \n",
      "Epoch [7130/10000], Loss: 0.2019, Train Acc: 0.9545, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|███████████████████▍       | 7180/10000 [00:16<00:06, 439.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7140/10000], Loss: 0.2017, Train Acc: 0.9546, \n",
      "Epoch [7150/10000], Loss: 0.2016, Train Acc: 0.9546, \n",
      "Epoch [7160/10000], Loss: 0.2014, Train Acc: 0.9546, \n",
      "Epoch [7170/10000], Loss: 0.2013, Train Acc: 0.9547, \n",
      "Epoch [7180/10000], Loss: 0.2011, Train Acc: 0.9548, \n",
      "Epoch [7190/10000], Loss: 0.2009, Train Acc: 0.9549, \n",
      "Epoch [7200/10000], Loss: 0.2008, Train Acc: 0.9549, \n",
      "Epoch [7210/10000], Loss: 0.2006, Train Acc: 0.9549, \n",
      "Epoch [7220/10000], Loss: 0.2005, Train Acc: 0.9549, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  73%|███████████████████▋       | 7314/10000 [00:17<00:06, 437.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7230/10000], Loss: 0.2003, Train Acc: 0.9550, \n",
      "Epoch [7240/10000], Loss: 0.2001, Train Acc: 0.9551, \n",
      "Epoch [7250/10000], Loss: 0.2000, Train Acc: 0.9552, \n",
      "Epoch [7260/10000], Loss: 0.1998, Train Acc: 0.9553, \n",
      "Epoch [7270/10000], Loss: 0.1996, Train Acc: 0.9553, \n",
      "Epoch [7280/10000], Loss: 0.1995, Train Acc: 0.9553, \n",
      "Epoch [7290/10000], Loss: 0.1993, Train Acc: 0.9554, \n",
      "Epoch [7300/10000], Loss: 0.1992, Train Acc: 0.9555, \n",
      "Epoch [7310/10000], Loss: 0.1990, Train Acc: 0.9555, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|███████████████████▊       | 7358/10000 [00:17<00:06, 435.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7320/10000], Loss: 0.1989, Train Acc: 0.9557, \n",
      "Epoch [7330/10000], Loss: 0.1987, Train Acc: 0.9557, \n",
      "Epoch [7340/10000], Loss: 0.1985, Train Acc: 0.9558, \n",
      "Epoch [7350/10000], Loss: 0.1984, Train Acc: 0.9559, \n",
      "Epoch [7360/10000], Loss: 0.1982, Train Acc: 0.9559, \n",
      "Epoch [7370/10000], Loss: 0.1981, Train Acc: 0.9560, \n",
      "Epoch [7380/10000], Loss: 0.1979, Train Acc: 0.9561, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|███████████████████▉       | 7402/10000 [00:17<00:09, 267.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7390/10000], Loss: 0.1977, Train Acc: 0.9561, \n",
      "Epoch [7400/10000], Loss: 0.1976, Train Acc: 0.9562, \n",
      "Epoch [7410/10000], Loss: 0.1974, Train Acc: 0.9563, \n",
      "Epoch [7420/10000], Loss: 0.1973, Train Acc: 0.9563, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|████████████████████▏      | 7486/10000 [00:17<00:07, 322.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7430/10000], Loss: 0.1971, Train Acc: 0.9564, \n",
      "Epoch [7440/10000], Loss: 0.1970, Train Acc: 0.9564, \n",
      "Epoch [7450/10000], Loss: 0.1968, Train Acc: 0.9565, \n",
      "Epoch [7460/10000], Loss: 0.1966, Train Acc: 0.9566, \n",
      "Epoch [7470/10000], Loss: 0.1965, Train Acc: 0.9566, \n",
      "Epoch [7480/10000], Loss: 0.1963, Train Acc: 0.9567, \n",
      "Epoch [7490/10000], Loss: 0.1962, Train Acc: 0.9568, \n",
      "Epoch [7500/10000], Loss: 0.1960, Train Acc: 0.9569, \n",
      "Epoch [7510/10000], Loss: 0.1959, Train Acc: 0.9569, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|████████████████████▍      | 7584/10000 [00:18<00:06, 397.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7520/10000], Loss: 0.1957, Train Acc: 0.9570, \n",
      "Epoch [7530/10000], Loss: 0.1956, Train Acc: 0.9570, \n",
      "Epoch [7540/10000], Loss: 0.1954, Train Acc: 0.9572, \n",
      "Epoch [7550/10000], Loss: 0.1952, Train Acc: 0.9572, \n",
      "Epoch [7560/10000], Loss: 0.1951, Train Acc: 0.9572, \n",
      "Epoch [7570/10000], Loss: 0.1949, Train Acc: 0.9572, \n",
      "Epoch [7580/10000], Loss: 0.1948, Train Acc: 0.9573, \n",
      "Epoch [7590/10000], Loss: 0.1946, Train Acc: 0.9573, \n",
      "Epoch [7600/10000], Loss: 0.1945, Train Acc: 0.9574, \n",
      "Epoch [7610/10000], Loss: 0.1943, Train Acc: 0.9575, \n",
      "Epoch [7620/10000], Loss: 0.1942, Train Acc: 0.9575, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|████████████████████▊      | 7687/10000 [00:18<00:05, 451.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7630/10000], Loss: 0.1940, Train Acc: 0.9576, \n",
      "Epoch [7640/10000], Loss: 0.1939, Train Acc: 0.9577, \n",
      "Epoch [7650/10000], Loss: 0.1937, Train Acc: 0.9577, \n",
      "Epoch [7660/10000], Loss: 0.1936, Train Acc: 0.9577, \n",
      "Epoch [7670/10000], Loss: 0.1934, Train Acc: 0.9578, \n",
      "Epoch [7680/10000], Loss: 0.1932, Train Acc: 0.9578, \n",
      "Epoch [7690/10000], Loss: 0.1931, Train Acc: 0.9579, \n",
      "Epoch [7700/10000], Loss: 0.1929, Train Acc: 0.9580, \n",
      "Epoch [7710/10000], Loss: 0.1928, Train Acc: 0.9581, \n",
      "Epoch [7720/10000], Loss: 0.1926, Train Acc: 0.9582, \n",
      "Epoch [7730/10000], Loss: 0.1925, Train Acc: 0.9583, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|█████████████████████▏     | 7838/10000 [00:18<00:04, 477.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7740/10000], Loss: 0.1923, Train Acc: 0.9583, \n",
      "Epoch [7750/10000], Loss: 0.1922, Train Acc: 0.9584, \n",
      "Epoch [7760/10000], Loss: 0.1920, Train Acc: 0.9585, \n",
      "Epoch [7770/10000], Loss: 0.1919, Train Acc: 0.9586, \n",
      "Epoch [7780/10000], Loss: 0.1917, Train Acc: 0.9586, \n",
      "Epoch [7790/10000], Loss: 0.1916, Train Acc: 0.9587, \n",
      "Epoch [7800/10000], Loss: 0.1914, Train Acc: 0.9588, \n",
      "Epoch [7810/10000], Loss: 0.1913, Train Acc: 0.9589, \n",
      "Epoch [7820/10000], Loss: 0.1911, Train Acc: 0.9589, \n",
      "Epoch [7830/10000], Loss: 0.1910, Train Acc: 0.9590, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  79%|█████████████████████▍     | 7939/10000 [00:18<00:04, 485.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7840/10000], Loss: 0.1908, Train Acc: 0.9591, \n",
      "Epoch [7850/10000], Loss: 0.1907, Train Acc: 0.9592, \n",
      "Epoch [7860/10000], Loss: 0.1905, Train Acc: 0.9594, \n",
      "Epoch [7870/10000], Loss: 0.1904, Train Acc: 0.9594, \n",
      "Epoch [7880/10000], Loss: 0.1902, Train Acc: 0.9595, \n",
      "Epoch [7890/10000], Loss: 0.1901, Train Acc: 0.9596, \n",
      "Epoch [7900/10000], Loss: 0.1899, Train Acc: 0.9597, \n",
      "Epoch [7910/10000], Loss: 0.1898, Train Acc: 0.9598, \n",
      "Epoch [7920/10000], Loss: 0.1896, Train Acc: 0.9600, \n",
      "Epoch [7930/10000], Loss: 0.1895, Train Acc: 0.9600, \n",
      "Epoch [7940/10000], Loss: 0.1894, Train Acc: 0.9601, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|█████████████████████▋     | 8040/10000 [00:18<00:03, 490.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7950/10000], Loss: 0.1892, Train Acc: 0.9603, \n",
      "Epoch [7960/10000], Loss: 0.1891, Train Acc: 0.9603, \n",
      "Epoch [7970/10000], Loss: 0.1889, Train Acc: 0.9604, \n",
      "Epoch [7980/10000], Loss: 0.1888, Train Acc: 0.9604, \n",
      "Epoch [7990/10000], Loss: 0.1886, Train Acc: 0.9605, \n",
      "Epoch [8000/10000], Loss: 0.1885, Train Acc: 0.9606, \n",
      "Epoch [8010/10000], Loss: 0.1883, Train Acc: 0.9608, \n",
      "Epoch [8020/10000], Loss: 0.1882, Train Acc: 0.9609, \n",
      "Epoch [8030/10000], Loss: 0.1880, Train Acc: 0.9611, \n",
      "Epoch [8040/10000], Loss: 0.1879, Train Acc: 0.9611, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  81%|█████████████████████▉     | 8145/10000 [00:19<00:03, 506.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8050/10000], Loss: 0.1877, Train Acc: 0.9612, \n",
      "Epoch [8060/10000], Loss: 0.1876, Train Acc: 0.9613, \n",
      "Epoch [8070/10000], Loss: 0.1875, Train Acc: 0.9614, \n",
      "Epoch [8080/10000], Loss: 0.1873, Train Acc: 0.9614, \n",
      "Epoch [8090/10000], Loss: 0.1872, Train Acc: 0.9615, \n",
      "Epoch [8100/10000], Loss: 0.1870, Train Acc: 0.9616, \n",
      "Epoch [8110/10000], Loss: 0.1869, Train Acc: 0.9617, \n",
      "Epoch [8120/10000], Loss: 0.1867, Train Acc: 0.9617, \n",
      "Epoch [8130/10000], Loss: 0.1866, Train Acc: 0.9618, \n",
      "Epoch [8140/10000], Loss: 0.1864, Train Acc: 0.9618, \n",
      "Epoch [8150/10000], Loss: 0.1863, Train Acc: 0.9619, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  82%|██████████████████████▎    | 8250/10000 [00:19<00:03, 513.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8160/10000], Loss: 0.1862, Train Acc: 0.9619, \n",
      "Epoch [8170/10000], Loss: 0.1860, Train Acc: 0.9620, \n",
      "Epoch [8180/10000], Loss: 0.1859, Train Acc: 0.9620, \n",
      "Epoch [8190/10000], Loss: 0.1857, Train Acc: 0.9621, \n",
      "Epoch [8200/10000], Loss: 0.1856, Train Acc: 0.9622, \n",
      "Epoch [8210/10000], Loss: 0.1854, Train Acc: 0.9622, \n",
      "Epoch [8220/10000], Loss: 0.1853, Train Acc: 0.9623, \n",
      "Epoch [8230/10000], Loss: 0.1851, Train Acc: 0.9623, \n",
      "Epoch [8240/10000], Loss: 0.1850, Train Acc: 0.9624, \n",
      "Epoch [8250/10000], Loss: 0.1849, Train Acc: 0.9624, \n",
      "Epoch [8260/10000], Loss: 0.1847, Train Acc: 0.9625, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  84%|██████████████████████▌    | 8354/10000 [00:19<00:03, 512.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8270/10000], Loss: 0.1846, Train Acc: 0.9626, \n",
      "Epoch [8280/10000], Loss: 0.1844, Train Acc: 0.9626, \n",
      "Epoch [8290/10000], Loss: 0.1843, Train Acc: 0.9626, \n",
      "Epoch [8300/10000], Loss: 0.1842, Train Acc: 0.9627, \n",
      "Epoch [8310/10000], Loss: 0.1840, Train Acc: 0.9627, \n",
      "Epoch [8320/10000], Loss: 0.1839, Train Acc: 0.9627, \n",
      "Epoch [8330/10000], Loss: 0.1837, Train Acc: 0.9627, \n",
      "Epoch [8340/10000], Loss: 0.1836, Train Acc: 0.9628, \n",
      "Epoch [8350/10000], Loss: 0.1834, Train Acc: 0.9628, \n",
      "Epoch [8360/10000], Loss: 0.1833, Train Acc: 0.9629, \n",
      "Epoch [8370/10000], Loss: 0.1832, Train Acc: 0.9629, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|██████████████████████▊    | 8459/10000 [00:19<00:03, 513.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8380/10000], Loss: 0.1830, Train Acc: 0.9629, \n",
      "Epoch [8390/10000], Loss: 0.1829, Train Acc: 0.9629, \n",
      "Epoch [8400/10000], Loss: 0.1827, Train Acc: 0.9630, \n",
      "Epoch [8410/10000], Loss: 0.1826, Train Acc: 0.9632, \n",
      "Epoch [8420/10000], Loss: 0.1825, Train Acc: 0.9633, \n",
      "Epoch [8430/10000], Loss: 0.1823, Train Acc: 0.9634, \n",
      "Epoch [8440/10000], Loss: 0.1822, Train Acc: 0.9635, \n",
      "Epoch [8450/10000], Loss: 0.1821, Train Acc: 0.9636, \n",
      "Epoch [8460/10000], Loss: 0.1819, Train Acc: 0.9637, \n",
      "Epoch [8470/10000], Loss: 0.1818, Train Acc: 0.9638, \n",
      "Epoch [8480/10000], Loss: 0.1816, Train Acc: 0.9638, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  86%|███████████████████████    | 8563/10000 [00:19<00:02, 508.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8490/10000], Loss: 0.1815, Train Acc: 0.9639, \n",
      "Epoch [8500/10000], Loss: 0.1814, Train Acc: 0.9639, \n",
      "Epoch [8510/10000], Loss: 0.1812, Train Acc: 0.9639, \n",
      "Epoch [8520/10000], Loss: 0.1811, Train Acc: 0.9640, \n",
      "Epoch [8530/10000], Loss: 0.1809, Train Acc: 0.9641, \n",
      "Epoch [8540/10000], Loss: 0.1808, Train Acc: 0.9642, \n",
      "Epoch [8550/10000], Loss: 0.1807, Train Acc: 0.9643, \n",
      "Epoch [8560/10000], Loss: 0.1805, Train Acc: 0.9643, \n",
      "Epoch [8570/10000], Loss: 0.1804, Train Acc: 0.9643, \n",
      "Epoch [8580/10000], Loss: 0.1803, Train Acc: 0.9643, \n",
      "Epoch [8590/10000], Loss: 0.1801, Train Acc: 0.9643, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  87%|███████████████████████▍   | 8665/10000 [00:20<00:02, 506.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8600/10000], Loss: 0.1800, Train Acc: 0.9644, \n",
      "Epoch [8610/10000], Loss: 0.1798, Train Acc: 0.9644, \n",
      "Epoch [8620/10000], Loss: 0.1797, Train Acc: 0.9646, \n",
      "Epoch [8630/10000], Loss: 0.1796, Train Acc: 0.9646, \n",
      "Epoch [8640/10000], Loss: 0.1794, Train Acc: 0.9647, \n",
      "Epoch [8650/10000], Loss: 0.1793, Train Acc: 0.9648, \n",
      "Epoch [8660/10000], Loss: 0.1792, Train Acc: 0.9649, \n",
      "Epoch [8670/10000], Loss: 0.1790, Train Acc: 0.9649, \n",
      "Epoch [8680/10000], Loss: 0.1789, Train Acc: 0.9649, \n",
      "Epoch [8690/10000], Loss: 0.1788, Train Acc: 0.9650, \n",
      "Epoch [8700/10000], Loss: 0.1786, Train Acc: 0.9651, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|███████████████████████▋   | 8769/10000 [00:20<00:02, 510.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8710/10000], Loss: 0.1785, Train Acc: 0.9651, \n",
      "Epoch [8720/10000], Loss: 0.1784, Train Acc: 0.9651, \n",
      "Epoch [8730/10000], Loss: 0.1782, Train Acc: 0.9652, \n",
      "Epoch [8740/10000], Loss: 0.1781, Train Acc: 0.9653, \n",
      "Epoch [8750/10000], Loss: 0.1780, Train Acc: 0.9653, \n",
      "Epoch [8760/10000], Loss: 0.1778, Train Acc: 0.9654, \n",
      "Epoch [8770/10000], Loss: 0.1777, Train Acc: 0.9654, \n",
      "Epoch [8780/10000], Loss: 0.1776, Train Acc: 0.9654, \n",
      "Epoch [8790/10000], Loss: 0.1774, Train Acc: 0.9654, \n",
      "Epoch [8800/10000], Loss: 0.1773, Train Acc: 0.9655, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  89%|███████████████████████▉   | 8873/10000 [00:20<00:02, 499.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8810/10000], Loss: 0.1772, Train Acc: 0.9655, \n",
      "Epoch [8820/10000], Loss: 0.1770, Train Acc: 0.9656, \n",
      "Epoch [8830/10000], Loss: 0.1769, Train Acc: 0.9657, \n",
      "Epoch [8840/10000], Loss: 0.1768, Train Acc: 0.9657, \n",
      "Epoch [8850/10000], Loss: 0.1766, Train Acc: 0.9657, \n",
      "Epoch [8860/10000], Loss: 0.1765, Train Acc: 0.9658, \n",
      "Epoch [8870/10000], Loss: 0.1764, Train Acc: 0.9659, \n",
      "Epoch [8880/10000], Loss: 0.1762, Train Acc: 0.9660, \n",
      "Epoch [8890/10000], Loss: 0.1761, Train Acc: 0.9660, \n",
      "Epoch [8900/10000], Loss: 0.1760, Train Acc: 0.9660, \n",
      "Epoch [8910/10000], Loss: 0.1758, Train Acc: 0.9661, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|████████████████████████▏  | 8978/10000 [00:20<00:02, 508.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8920/10000], Loss: 0.1757, Train Acc: 0.9662, \n",
      "Epoch [8930/10000], Loss: 0.1756, Train Acc: 0.9663, \n",
      "Epoch [8940/10000], Loss: 0.1754, Train Acc: 0.9663, \n",
      "Epoch [8950/10000], Loss: 0.1753, Train Acc: 0.9663, \n",
      "Epoch [8960/10000], Loss: 0.1752, Train Acc: 0.9664, \n",
      "Epoch [8970/10000], Loss: 0.1750, Train Acc: 0.9664, \n",
      "Epoch [8980/10000], Loss: 0.1749, Train Acc: 0.9665, \n",
      "Epoch [8990/10000], Loss: 0.1748, Train Acc: 0.9665, \n",
      "Epoch [9000/10000], Loss: 0.1746, Train Acc: 0.9666, \n",
      "Epoch [9010/10000], Loss: 0.1745, Train Acc: 0.9667, \n",
      "Epoch [9020/10000], Loss: 0.1744, Train Acc: 0.9667, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  91%|████████████████████████▋  | 9133/10000 [00:21<00:01, 511.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9030/10000], Loss: 0.1743, Train Acc: 0.9668, \n",
      "Epoch [9040/10000], Loss: 0.1741, Train Acc: 0.9669, \n",
      "Epoch [9050/10000], Loss: 0.1740, Train Acc: 0.9669, \n",
      "Epoch [9060/10000], Loss: 0.1739, Train Acc: 0.9670, \n",
      "Epoch [9070/10000], Loss: 0.1737, Train Acc: 0.9670, \n",
      "Epoch [9080/10000], Loss: 0.1736, Train Acc: 0.9670, \n",
      "Epoch [9090/10000], Loss: 0.1735, Train Acc: 0.9671, \n",
      "Epoch [9100/10000], Loss: 0.1733, Train Acc: 0.9672, \n",
      "Epoch [9110/10000], Loss: 0.1732, Train Acc: 0.9672, \n",
      "Epoch [9120/10000], Loss: 0.1731, Train Acc: 0.9674, \n",
      "Epoch [9130/10000], Loss: 0.1730, Train Acc: 0.9674, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|████████████████████████▊  | 9185/10000 [00:21<00:01, 512.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9140/10000], Loss: 0.1728, Train Acc: 0.9674, \n",
      "Epoch [9150/10000], Loss: 0.1727, Train Acc: 0.9675, \n",
      "Epoch [9160/10000], Loss: 0.1726, Train Acc: 0.9675, \n",
      "Epoch [9170/10000], Loss: 0.1724, Train Acc: 0.9675, \n",
      "Epoch [9180/10000], Loss: 0.1723, Train Acc: 0.9676, \n",
      "Epoch [9190/10000], Loss: 0.1722, Train Acc: 0.9676, \n",
      "Epoch [9200/10000], Loss: 0.1721, Train Acc: 0.9678, \n",
      "Epoch [9210/10000], Loss: 0.1719, Train Acc: 0.9678, \n",
      "Epoch [9220/10000], Loss: 0.1718, Train Acc: 0.9678, \n",
      "Epoch [9230/10000], Loss: 0.1717, Train Acc: 0.9679, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  93%|█████████████████████████  | 9286/10000 [00:21<00:01, 482.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9240/10000], Loss: 0.1716, Train Acc: 0.9680, \n",
      "Epoch [9250/10000], Loss: 0.1714, Train Acc: 0.9680, \n",
      "Epoch [9260/10000], Loss: 0.1713, Train Acc: 0.9681, \n",
      "Epoch [9270/10000], Loss: 0.1712, Train Acc: 0.9681, \n",
      "Epoch [9280/10000], Loss: 0.1710, Train Acc: 0.9682, \n",
      "Epoch [9290/10000], Loss: 0.1709, Train Acc: 0.9683, \n",
      "Epoch [9300/10000], Loss: 0.1708, Train Acc: 0.9685, \n",
      "Epoch [9310/10000], Loss: 0.1707, Train Acc: 0.9685, \n",
      "Epoch [9320/10000], Loss: 0.1705, Train Acc: 0.9685, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████████████████████▎ | 9382/10000 [00:21<00:01, 448.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9330/10000], Loss: 0.1704, Train Acc: 0.9686, \n",
      "Epoch [9340/10000], Loss: 0.1703, Train Acc: 0.9687, \n",
      "Epoch [9350/10000], Loss: 0.1702, Train Acc: 0.9687, \n",
      "Epoch [9360/10000], Loss: 0.1700, Train Acc: 0.9688, \n",
      "Epoch [9370/10000], Loss: 0.1699, Train Acc: 0.9689, \n",
      "Epoch [9380/10000], Loss: 0.1698, Train Acc: 0.9690, \n",
      "Epoch [9390/10000], Loss: 0.1697, Train Acc: 0.9690, \n",
      "Epoch [9400/10000], Loss: 0.1695, Train Acc: 0.9690, \n",
      "Epoch [9410/10000], Loss: 0.1694, Train Acc: 0.9691, \n",
      "Epoch [9420/10000], Loss: 0.1693, Train Acc: 0.9691, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|█████████████████████████▌ | 9478/10000 [00:21<00:01, 462.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9430/10000], Loss: 0.1692, Train Acc: 0.9691, \n",
      "Epoch [9440/10000], Loss: 0.1690, Train Acc: 0.9692, \n",
      "Epoch [9450/10000], Loss: 0.1689, Train Acc: 0.9693, \n",
      "Epoch [9460/10000], Loss: 0.1688, Train Acc: 0.9693, \n",
      "Epoch [9470/10000], Loss: 0.1687, Train Acc: 0.9694, \n",
      "Epoch [9480/10000], Loss: 0.1685, Train Acc: 0.9694, \n",
      "Epoch [9490/10000], Loss: 0.1684, Train Acc: 0.9694, \n",
      "Epoch [9500/10000], Loss: 0.1683, Train Acc: 0.9694, \n",
      "Epoch [9510/10000], Loss: 0.1682, Train Acc: 0.9695, \n",
      "Epoch [9520/10000], Loss: 0.1681, Train Acc: 0.9695, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  96%|█████████████████████████▊ | 9578/10000 [00:22<00:00, 463.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9530/10000], Loss: 0.1679, Train Acc: 0.9697, \n",
      "Epoch [9540/10000], Loss: 0.1678, Train Acc: 0.9697, \n",
      "Epoch [9550/10000], Loss: 0.1677, Train Acc: 0.9697, \n",
      "Epoch [9560/10000], Loss: 0.1676, Train Acc: 0.9698, \n",
      "Epoch [9570/10000], Loss: 0.1674, Train Acc: 0.9699, \n",
      "Epoch [9580/10000], Loss: 0.1673, Train Acc: 0.9699, \n",
      "Epoch [9590/10000], Loss: 0.1672, Train Acc: 0.9699, \n",
      "Epoch [9600/10000], Loss: 0.1671, Train Acc: 0.9700, \n",
      "Epoch [9610/10000], Loss: 0.1670, Train Acc: 0.9701, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|██████████████████████████ | 9670/10000 [00:22<00:00, 438.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9620/10000], Loss: 0.1668, Train Acc: 0.9702, \n",
      "Epoch [9630/10000], Loss: 0.1667, Train Acc: 0.9703, \n",
      "Epoch [9640/10000], Loss: 0.1666, Train Acc: 0.9704, \n",
      "Epoch [9650/10000], Loss: 0.1665, Train Acc: 0.9704, \n",
      "Epoch [9660/10000], Loss: 0.1663, Train Acc: 0.9705, \n",
      "Epoch [9670/10000], Loss: 0.1662, Train Acc: 0.9706, \n",
      "Epoch [9680/10000], Loss: 0.1661, Train Acc: 0.9706, \n",
      "Epoch [9690/10000], Loss: 0.1660, Train Acc: 0.9706, \n",
      "Epoch [9700/10000], Loss: 0.1659, Train Acc: 0.9706, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|██████████████████████████▎| 9766/10000 [00:22<00:00, 457.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9710/10000], Loss: 0.1657, Train Acc: 0.9707, \n",
      "Epoch [9720/10000], Loss: 0.1656, Train Acc: 0.9707, \n",
      "Epoch [9730/10000], Loss: 0.1655, Train Acc: 0.9708, \n",
      "Epoch [9740/10000], Loss: 0.1654, Train Acc: 0.9709, \n",
      "Epoch [9750/10000], Loss: 0.1653, Train Acc: 0.9709, \n",
      "Epoch [9760/10000], Loss: 0.1651, Train Acc: 0.9709, \n",
      "Epoch [9770/10000], Loss: 0.1650, Train Acc: 0.9710, \n",
      "Epoch [9780/10000], Loss: 0.1649, Train Acc: 0.9711, \n",
      "Epoch [9790/10000], Loss: 0.1648, Train Acc: 0.9711, \n",
      "Epoch [9800/10000], Loss: 0.1647, Train Acc: 0.9712, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|██████████████████████████▋| 9863/10000 [00:22<00:00, 470.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9810/10000], Loss: 0.1645, Train Acc: 0.9712, \n",
      "Epoch [9820/10000], Loss: 0.1644, Train Acc: 0.9713, \n",
      "Epoch [9830/10000], Loss: 0.1643, Train Acc: 0.9714, \n",
      "Epoch [9840/10000], Loss: 0.1642, Train Acc: 0.9715, \n",
      "Epoch [9850/10000], Loss: 0.1641, Train Acc: 0.9715, \n",
      "Epoch [9860/10000], Loss: 0.1640, Train Acc: 0.9716, \n",
      "Epoch [9870/10000], Loss: 0.1638, Train Acc: 0.9716, \n",
      "Epoch [9880/10000], Loss: 0.1637, Train Acc: 0.9716, \n",
      "Epoch [9890/10000], Loss: 0.1636, Train Acc: 0.9717, \n",
      "Epoch [9900/10000], Loss: 0.1635, Train Acc: 0.9718, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████| 10000/10000 [00:22<00:00, 435.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9910/10000], Loss: 0.1634, Train Acc: 0.9718, \n",
      "Epoch [9920/10000], Loss: 0.1632, Train Acc: 0.9718, \n",
      "Epoch [9930/10000], Loss: 0.1631, Train Acc: 0.9719, \n",
      "Epoch [9940/10000], Loss: 0.1630, Train Acc: 0.9720, \n",
      "Epoch [9950/10000], Loss: 0.1629, Train Acc: 0.9720, \n",
      "Epoch [9960/10000], Loss: 0.1628, Train Acc: 0.9721, \n",
      "Epoch [9970/10000], Loss: 0.1627, Train Acc: 0.9722, \n",
      "Epoch [9980/10000], Loss: 0.1625, Train Acc: 0.9723, \n",
      "Epoch [9990/10000], Loss: 0.1624, Train Acc: 0.9724, \n",
      "Epoch [10000/10000], Loss: 0.1623, Train Acc: 0.9724, \n",
      "<generator object Module.parameters at 0x1600d67a0>\n",
      "[0 1]\n",
      "[0. 1.]\n",
      "accuracy: 0.9610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dqs, accs = {}, {}\n",
    "float_preds_list, preds_list = [], []\n",
    "# 0.001, 0.01, 0.1, 0.5, 1, 2, 3, 5,\n",
    "n = X_train.shape[0]\n",
    "# k = 1\n",
    "Lamb = 0.0001\n",
    "# [0.1, 0.3, 0.5, 0.7, 0.9, 1, 2, 3, 5, 10]\n",
    "# 0.1, 0.5, 1, 3, 5, 10, \n",
    "for eps_p in [np.inf]:\n",
    "    dq_list, acc_list = [], []\n",
    "    for _ in range(1):\n",
    "\n",
    "\n",
    "#         model = twostg_train_model(X_train, y_train, eps_p, \\\n",
    "#                                    lr=best_params['learning_rate'], \\\n",
    "#                                    weight_decay=best_params['weight_decay'], \\\n",
    "#                                    epochs=100)\n",
    "\n",
    "        model_trained = twostg_train_model(\n",
    "                X_train=X_train,\n",
    "                y_train=y_train,\n",
    "                eps_p=eps_p,\n",
    "                lr=1e-3,\n",
    "                epochs=10000,\n",
    "                Lamb=Lamb,\n",
    "            )\n",
    "    \n",
    "        print(model_trained.parameters())\n",
    "    \n",
    "        X_test, y_test = X_test[:1000], y_test[:1000]\n",
    "        print(np.unique(y_test))\n",
    "\n",
    "\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "        y_test = np.array(y_test)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "\n",
    "        # Evaluation\n",
    "        with torch.no_grad():\n",
    "\n",
    "            y_predicted = model_trained(X_test_tensor)\n",
    "            y_predicted_cls = y_predicted.round()\n",
    "            print(np.unique(y_predicted_cls))\n",
    "            acc = y_predicted_cls.eq(y_test_tensor).sum() / float(y_test_tensor.shape[0])\n",
    "            acc_list.append(acc)\n",
    "            print(f'accuracy: {acc.item():.4f}')\n",
    "\n",
    "        preds_list.append(np.array(y_predicted_cls))\n",
    "        float_preds_list.append(np.array(y_predicted))\n",
    "        \n",
    "#         print(y_predicted_cls)\n",
    "\n",
    "#         z_star = run_opt(np.array(y_predicted))\n",
    "\n",
    "#         dq = np.dot(z_star.flatten(), y_test)\n",
    "#         dq_list.append(dq)\n",
    "        \n",
    "        \n",
    "#     dqs[f'{eps_p}'] = np.mean(dq_list)\n",
    "#     accs[f'{eps_p}'] = np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix  # Optional for sparse matrices\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB  # Ensure GRB is imported\n",
    "\n",
    "\n",
    "# Example data\n",
    "# G = np.random.rand(100, 50)  # A 100x50 matrix\n",
    "# h = np.random.rand(100)      # RHS vector\n",
    "\n",
    "def run_opt(y_hat):\n",
    "\n",
    "    newn = y_hat.shape[0]  # Number of variables (columns in G)\n",
    "    print(newn)\n",
    "\n",
    "    model = gp.Model(\"matrix_constraints\")\n",
    "\n",
    "    z = model.addMVar(newn, lb=-GRB.INFINITY, ub=GRB.INFINITY, name=\"z\")  # MVar for vectorized variables\n",
    "    \n",
    "    # Budget constraint\n",
    "    B = newn // 2 \n",
    "\n",
    "    model.addConstr(z.sum() <= B, name=\"sum_constraint\")\n",
    "    \n",
    "    \n",
    "    o, p = np.identity(newn), -np.identity(newn)\n",
    "    G = np.concatenate((o, p), axis=0)\n",
    "\n",
    "    h_1, h_2 = np.ones(newn), np.zeros(newn)\n",
    "    h_1, h_2 = h_1.reshape(-1,1), h_2.reshape(-1,1)\n",
    "    h = np.concatenate((h_1, h_2), axis=0)\n",
    "\n",
    "\n",
    "    print(G.shape)\n",
    "    print(z.shape)\n",
    "    print(h.shape)\n",
    "    \n",
    "    z = z.reshape(-1, 1)\n",
    "    \n",
    "    model.addConstr(G @ z <= h)\n",
    "\n",
    "    y_hat = y_hat.flatten()\n",
    "    \n",
    "    dot_product = gp.quicksum(y_hat[i] * z[i] for i in range(len(y_hat)))\n",
    "    \n",
    "\n",
    "    model.setObjective(dot_product, GRB.MAXIMIZE)\n",
    "\n",
    "    model.optimize()\n",
    "\n",
    "    if model.status == GRB.OPTIMAL:\n",
    "        z_star_test = z.X\n",
    "        \n",
    "    return z_star_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([205.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_predicted_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([240.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2585225\n",
      "Academic license - for non-commercial use only - expires 2025-11-15\n",
      "(2000, 1000)\n",
      "(1000,)\n",
      "(2000, 1)\n",
      "Gurobi Optimizer version 12.0.0 build v12.0.0rc1 (mac64[arm] - Darwin 24.3.0 24D70)\n",
      "\n",
      "CPU model: Apple M1\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 2001 rows, 1000 columns and 3000 nonzeros\n",
      "Model fingerprint: 0xc74c9de3\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+00, 5e+02]\n",
      "Presolve removed 2001 rows and 1000 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    2.0500000e+02   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.00 seconds (0.00 work units)\n",
      "Optimal objective  2.050000000e+02\n"
     ]
    }
   ],
   "source": [
    "z_star = run_opt(np.array(y_predicted_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dq = np.dot(z_star.flatten(), y_test)\n",
    "dq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
